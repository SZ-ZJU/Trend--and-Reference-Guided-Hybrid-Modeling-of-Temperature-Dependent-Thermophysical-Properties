# import pandas as pd
# import numpy as np
# from sklearn.linear_model import HuberRegressor
# from sklearn.ensemble import RandomForestRegressor
# from sklearn.preprocessing import PolynomialFeatures
# from sklearn.metrics import mean_squared_error, r2_score
#
# # 1. è¯»å–æ•°æ®
# file_path = "heat capacity 207.xlsx"
# df = pd.read_excel(file_path, sheet_name="Sheet1")
# df = df.dropna(subset=[df.columns[0]]).reset_index(drop=True)  # ä¿è¯è¡Œç´¢å¼•è¿ç»­ï¼Œä¸ä½ çš„ X_poly_all å¯¹é½
# df[df.columns[0]] = df[df.columns[0]].astype(int)
#
# # 2. åˆ—å®šä¹‰
# group_cols = df.columns[11:30]   # ä½ ä»£ç ä¸­çš„â€œåŸºå›¢åˆ—â€åˆ‡ç‰‡
# temp_cols  = df.columns[30:40]   # 10ä¸ªæ¸©åº¦ç‚¹
# cp_cols    = df.columns[40:50]   # 10ä¸ª Cp åˆ—ï¼ˆä½†ä½ è®­ç»ƒ Cp1/Cp2 ç”¨çš„æ˜¯ä¸‹é¢ä¸¤ä¸ªç»å¯¹åˆ—ç´¢å¼•ï¼‰
# target_column_T1 = 'ASPEN Half Critical T'
# Tc0 = 138.0
#
# # === æ–°å¢ï¼šç¬¬57/59åˆ—çš„ä½ç½®ï¼ˆ0-based ç´¢å¼•ï¼‰===
# CP0_COL_0BASED = 56  # BEåˆ—
# CP3_COL_0BASED = 58  # BGåˆ—
#
# # 3. å­æ¨¡å‹è®­ç»ƒï¼šç”¨äºä¼°ç®— T1, Cp0, Cp1, Cp2, Cp3 â†’ è®¡ç®—ä¸‰æ®µæ–œç‡
# X_groups = df[group_cols]
# valid_mask = ~df[target_column_T1].isna()
# poly = PolynomialFeatures(degree=2, include_bias=False)
# X_poly = poly.fit_transform(X_groups[valid_mask])
# y_exp_T1 = np.exp(df.loc[valid_mask, target_column_T1] / Tc0)
#
# T1_model  = HuberRegressor(max_iter=9000).fit(X_poly, y_exp_T1)
#
# # ä¿æŒä½ åŸæœ¬çš„ä¸¤åˆ—ç›®æ ‡ï¼šCp1 â† df.iloc[:, 9]ï¼›Cp2 â† df.iloc[:, 50]
# Cp1_model = HuberRegressor(max_iter=9000).fit(X_groups, df.iloc[:, 9])
# Cp2_model = HuberRegressor(max_iter=9000).fit(X_groups, df.iloc[:, 50])
#
# # === æ–°å¢ï¼šCp0/Cp3 æ¨¡å‹ï¼ˆç¬¬57/59åˆ—ï¼‰===
# Cp0_model = HuberRegressor(max_iter=9000).fit(X_groups, df.iloc[:, CP0_COL_0BASED])
# Cp3_model = HuberRegressor(max_iter=9000).fit(X_groups, df.iloc[:, CP3_COL_0BASED])
#
# # 4. æ„å»ºè®­ç»ƒæ•°æ®ï¼ˆæŠŠ slope*T æ¢æˆâ€œä¸‰æ®µé—¨æ§â€ç‰¹å¾ï¼‰
# X_total, y_total, material_ids, temperatures = [], [], [], []
# X_poly_all = poly.transform(X_groups)
# eps = 1e-8  # é˜²é™¤é›¶
#
# for i, row in df.iterrows():
#     material_id = row.iloc[0]
#     Nk    = row[group_cols].values.astype(float)
#     temps = row[temp_cols].values.astype(float)
#     cps   = row[cp_cols].values.astype(float)
#
#     Nk_df   = pd.DataFrame([Nk], columns=group_cols)
#     Nk_poly = X_poly_all[i:i+1]
#
#     try:
#         # â€” 4.1 é¢„æµ‹ T1ï¼ˆç”± T1_model ï¼‰ï¼Œå¹¶æ„é€  T0/T2/T3
#         T1_exp = T1_model.predict(Nk_poly)[0]
#         if (T1_exp <= 0) or (not np.isfinite(T1_exp)):
#             continue
#         T1 = Tc0 * np.log(T1_exp)
#         T2 = T1 * 1.5
#         T0 = T1 - 50.0         # ä½ çš„è®¾å®š
#         T3 = T2 + 30.0         # ä½ çš„è®¾å®š
#
#         # â€” 4.2 é¢„æµ‹å››ä¸ªå‚è€ƒç‚¹çš„ Cp
#         C0 = float(Cp0_model.predict(Nk_df)[0])  # ç¬¬57åˆ—ï¼ˆBEï¼‰
#         C1 = float(Cp1_model.predict(Nk_df)[0])  # ä½ åŸæ¥ç”¨çš„ç¬¬ 10 åˆ—ï¼ˆ0-based 9ï¼‰
#         C2 = float(Cp2_model.predict(Nk_df)[0])  # ä½ åŸæ¥ç”¨çš„ç¬¬ 51 åˆ—ï¼ˆ0-based 50ï¼‰
#         C3 = float(Cp3_model.predict(Nk_df)[0])  # ç¬¬59åˆ—ï¼ˆBGï¼‰
#
#         # â€” 4.3 ä¸‰æ®µæ–œç‡
#         s01 = (C1 - C0) / max(T1 - T0, eps)
#         s12 = (C2 - C1) / max(T2 - T1, eps)
#         s23 = (C3 - C2) / max(T3 - T2, eps)
#
#     except Exception:
#         continue
#
#     # â€” 4.4 éå†è¯¥ç‰©è´¨çš„æ¸©åº¦ç‚¹ï¼Œæ„é€ ä¸‰æ®µâ€œé—¨æ§â€ç‰¹å¾ï¼ˆåªæ¿€æ´»æ‰€åœ¨åˆ†æ®µï¼‰
#     for T, Cp in zip(temps, cps):
#         if np.isnan(T) or np.isnan(Cp):
#             continue
#
#         # æ¨èï¼šæ–œç‡ Ã— åˆ°æŠ˜ç‚¹çš„â€œè·ç¦»â€ï¼Œæ›´è´´ç‰©ç†ï¼›è¾¹ç•Œå½’ä¸­æ®µ
#         if T < T1:
#             zL, zM, zR = s01 * (T - T1), 0.0, 0.0
#         elif T >= T2:
#             zL, zM, zR = 0.0, s12 * (T - T1), 0.0
#         else:
#             zL, zM, zR = 0.0, 0.0, s23 * (T - T2)
#
#         features = np.concatenate([
#             Nk,           # åŸºå›¢
#             [T],          # å½“å‰æ¸©åº¦
#             [zL, zM, zR]  # ä¸‰æ®µé—¨æ§ç‰¹å¾ï¼ˆæ›¿ä»£åŸæ¥çš„ slope*Tï¼‰
#         ])
#
#         X_total.append(features)
#         y_total.append(Cp)
#         material_ids.append(material_id)
#         temperatures.append(T)
#
# X_total = np.array(X_total, dtype=float)
# y_total = np.array(y_total, dtype=float)
#
# # 5. æ‹Ÿåˆæœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆéšæœºæ£®æ—ï¼‰
# model = RandomForestRegressor(n_estimators=100, random_state=42)
# model.fit(X_total, y_total)
#
# # 6. è¯„ä¼°æ¨¡å‹
# y_pred = model.predict(X_total)
# mse = mean_squared_error(y_total, y_pred)
# r2  = r2_score(y_total, y_pred)
# ard = np.mean(np.abs((y_total - y_pred) / (np.abs(y_total) + eps))) * 100  # åŠ  eps æ›´ç¨³
#
# # === è¯¯å·®èŒƒå›´ç»Ÿè®¡ ===
# relative_error = np.abs((y_total - y_pred) / (np.abs(y_total) + eps)) * 100
# within_1pct  = np.sum(relative_error <= 1)
# within_5pct  = np.sum(relative_error <= 5)
# within_10pct = np.sum(relative_error <= 10)
#
# print("\nğŸ“Š æ¨¡å‹è¯„ä¼°ï¼ˆåˆ†æ®µé—¨æ§ç‰¹å¾ï¼‰ï¼š")
# print(f"RÂ²  = {r2:.4f}")
# print(f"MSE = {mse:.2f}")
# print(f"ARD = {ard:.2f}%")
# print(f"âœ… è¯¯å·® â‰¤ 1% çš„ç‚¹æ•°:  {within_1pct}")
# print(f"âœ… è¯¯å·® â‰¤ 5% çš„ç‚¹æ•°:  {within_5pct}")
# print(f"âœ… è¯¯å·® â‰¤ 10% çš„ç‚¹æ•°: {within_10pct}")
#
# # 7. ä¿å­˜é¢„æµ‹ç»“æœ
# results = pd.DataFrame({
#     "Material_ID": material_ids,
#     "Temperature (K)": temperatures,
#     "Cp_measured": y_total,
#     "Cp_predicted": y_pred
# })
# results.to_excel("Cpé¢„æµ‹ç»“æœ_åˆ†æ®µé—¨æ§_RFæ¨¡å‹.xlsx", index=False)
# print("âœ… å·²ä¿å­˜é¢„æµ‹ç»“æœä¸º: Cpé¢„æµ‹ç»“æœ_åˆ†æ®µé—¨æ§_RFæ¨¡å‹.xlsx")


import pandas as pd
import numpy as np
from sklearn.linear_model import HuberRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score

# 1. è¯»å–æ•°æ®
file_path = "heat capacity 207.xlsx"
df = pd.read_excel(file_path, sheet_name="Sheet1")
df = df.dropna(subset=[df.columns[0]]).reset_index(drop=True)  # ä¿è¯è¡Œç´¢å¼•è¿ç»­
df[df.columns[0]] = df[df.columns[0]].astype(int)

# 2. åˆ—å®šä¹‰
group_cols = df.columns[11:30]   # åŸºå›¢åˆ—
temp_cols  = df.columns[30:40]   # 10ä¸ªæ¸©åº¦ç‚¹
cp_cols    = df.columns[40:50]   # 10ä¸ª Cp åˆ—ï¼ˆç”¨äº y_totalï¼‰
target_column_T1 = 'ASPEN Half Critical T'
Tc0 = 138.0

# ç¬¬57/59åˆ—ï¼ˆExcel 1-basedï¼‰â†’ 0-based ç´¢å¼•
CP0_COL_0BASED = 56  # BE
CP3_COL_0BASED = 58  # BG

# 3. å­æ¨¡å‹è®­ç»ƒï¼šT1, Cp0, Cp1, Cp2, Cp3
X_groups = df[group_cols]
valid_mask = ~df[target_column_T1].isna()
poly = PolynomialFeatures(degree=2, include_bias=False)
X_poly = poly.fit_transform(X_groups[valid_mask])
y_exp_T1 = np.exp(df.loc[valid_mask, target_column_T1] / Tc0)
T1_model = HuberRegressor(max_iter=9000).fit(X_poly, y_exp_T1)

# â€”â€” é€šç”¨ï¼šå¸¦æ•°å€¼åŒ–ä¸æ©ç è¿‡æ»¤çš„æ‹Ÿåˆå‡½æ•°ï¼ˆé¿å… y ä¸­ NaNï¼‰â€”â€”
def fit_huber_on_col(col_idx: int) -> HuberRegressor:
    y_raw = df.iloc[:, col_idx]
    y_num = pd.to_numeric(y_raw, errors="coerce")                # æ–‡æœ¬/#N/A/ç©ºç™½ â†’ NaN
    mask = y_num.notna() & X_groups.notna().all(axis=1)          # è¿‡æ»¤ y ä¸º NaN æˆ–ç‰¹å¾ç¼ºå¤±çš„è¡Œ
    if mask.sum() == 0:
        raise ValueError(f"åˆ— {col_idx} è¿‡æ»¤åæ— æœ‰æ•ˆæ ·æœ¬ï¼Œæ— æ³•è®­ç»ƒã€‚")
    return HuberRegressor(max_iter=9000).fit(X_groups.loc[mask], y_num.loc[mask])

# ä½ åŸæ¥ç”¨çš„ä¸¤åˆ—ï¼šç¬¬10åˆ—(0-based 9)ã€ç¬¬51åˆ—(0-based 50)
Cp1_model = fit_huber_on_col(9)
Cp2_model = fit_huber_on_col(50)

# æ–°å¢ä¸¤åˆ—ï¼šç¬¬57/59åˆ—ï¼ˆ0-based 56/58ï¼‰
Cp0_model = fit_huber_on_col(CP0_COL_0BASED)
Cp3_model = fit_huber_on_col(CP3_COL_0BASED)

# 4. æ„å»ºè®­ç»ƒæ•°æ®ï¼ˆæŠŠ slope*T æ¢æˆâ€œä¸‰æ®µé—¨æ§â€ç‰¹å¾ï¼‰
X_total, y_total, material_ids, temperatures = [], [], [], []
X_poly_all = poly.transform(X_groups)
eps = 1e-8  # æ•°å€¼ä¿æŠ¤

for i, row in df.iterrows():
    material_id = row.iloc[0]
    Nk    = row[group_cols].values.astype(float)
    temps = row[temp_cols].values.astype(float)
    cps   = row[cp_cols].values.astype(float)

    Nk_df   = pd.DataFrame([Nk], columns=group_cols)
    Nk_poly = X_poly_all[i:i+1]

    try:
        # â€” 4.1 é¢„æµ‹ T1ï¼Œå¹¶æ„é€  T0/T2/T3
        T1_exp = T1_model.predict(Nk_poly)[0]
        if (T1_exp <= 0) or (not np.isfinite(T1_exp)):
            continue
        T1 = Tc0 * np.log(T1_exp)
        T2 = 1.5 * T1
        T0 = T1 - 50.0
        T3 = T2 + 30.0

        # â€” 4.2 é¢„æµ‹å››ä¸ªå‚è€ƒç‚¹çš„ Cp
        C0 = float(Cp0_model.predict(Nk_df)[0])  # ç¬¬57åˆ—ï¼ˆBEï¼‰
        C1 = float(Cp1_model.predict(Nk_df)[0])  # ç¬¬10åˆ—ï¼ˆ0-based 9ï¼‰
        C2 = float(Cp2_model.predict(Nk_df)[0])  # ç¬¬51åˆ—ï¼ˆ0-based 50ï¼‰
        C3 = float(Cp3_model.predict(Nk_df)[0])  # ç¬¬59åˆ—ï¼ˆBGï¼‰

        # â€” 4.3 ä¸‰æ®µæ–œç‡
        s01 = (C1 - C0) / max(T1 - T0, eps)
        s12 = (C2 - C1) / max(T2 - T1, eps)
        s23 = (C3 - C2) / max(T3 - T2, eps)

    except Exception:
        continue

    # â€” 4.4 ä¸‰æ®µâ€œé—¨æ§â€ç‰¹å¾ï¼ˆåªæ¿€æ´»æ‰€åœ¨åˆ†æ®µï¼‰
    for T, Cp in zip(temps, cps):
        if not (np.isfinite(T) and np.isfinite(Cp)):
            continue

        # æ­£ç¡®çš„åˆ†æ®µï¼šå·¦æ®µ T<T1ï¼›ä¸­æ®µ T1â‰¤Tâ‰¤T2ï¼›å³æ®µ T>T2
        if T < T1:
            zL, zM, zR = s01 * (T - T1), 0.0, 0.0
        elif T <= T2:
            zL, zM, zR = 0.0, s12 * (T - T1), 0.0
        else:
            zL, zM, zR = 0.0, 0.0, s23 * (T - T2)

        features = np.concatenate([Nk, [T, zL, zM, zR]])
        X_total.append(features)
        y_total.append(Cp)
        material_ids.append(material_id)
        temperatures.append(T)

X_total = np.array(X_total, dtype=float)
y_total = np.array(y_total, dtype=float)

# 5. æ‹Ÿåˆæœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆéšæœºæ£®æ—ï¼‰
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_total, y_total)

# 6. è¯„ä¼°æ¨¡å‹ï¼ˆè®­ç»ƒé›†ä¸Šï¼‰
y_pred = model.predict(X_total)
mse = mean_squared_error(y_total, y_pred)
r2  = r2_score(y_total, y_pred)
rel_err = np.abs((y_total - y_pred) / (np.abs(y_total) + eps)) * 100
ard = rel_err.mean()

within_1pct  = (rel_err <= 1).sum()
within_5pct  = (rel_err <= 5).sum()
within_10pct = (rel_err <= 10).sum()

print("\nğŸ“Š æ¨¡å‹è¯„ä¼°ï¼ˆåˆ†æ®µé—¨æ§ç‰¹å¾ï¼‰ï¼š")
print(f"RÂ²  = {r2:.4f}")
print(f"MSE = {mse:.2f}")
print(f"ARD = {ard:.2f}%")
print(f"âœ… è¯¯å·® â‰¤ 1% çš„ç‚¹æ•°:  {within_1pct}")
print(f"âœ… è¯¯å·® â‰¤ 5% çš„ç‚¹æ•°:  {within_5pct}")
print(f"âœ… è¯¯å·® â‰¤ 10% çš„ç‚¹æ•°: {within_10pct}")

# 7. ä¿å­˜é¢„æµ‹ç»“æœ
results = pd.DataFrame({
    "Material_ID": material_ids,
    "Temperature (K)": temperatures,
    "Cp_measured": y_total,
    "Cp_predicted": y_pred
})
results.to_excel("Cpé¢„æµ‹ç»“æœ_åˆ†æ®µé—¨æ§_RFæ¨¡å‹.xlsx", index=False)
print("âœ… å·²ä¿å­˜é¢„æµ‹ç»“æœä¸º: Cpé¢„æµ‹ç»“æœ_åˆ†æ®µé—¨æ§_RFæ¨¡å‹.xlsx")
