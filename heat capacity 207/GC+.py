# import pandas as pd
# import numpy as np
# from sklearn.linear_model import HuberRegressor
# from sklearn.preprocessing import PolynomialFeatures
# from sklearn.metrics import mean_squared_error, r2_score
#
# # ========= 1. è¯»å–æ•°æ® =========
# file_path = "heat capacity 207.xlsx"
# df = pd.read_excel(file_path, sheet_name="Sheet1")
# df = df.dropna(subset=[df.columns[0]])
# df[df.columns[0]] = df[df.columns[0]].astype(int)
#
# # ========= 2. åˆ—å®šä¹‰ =========
# group_cols = df.columns[11:30]   # 19ä¸ªåŸºå›¢åˆ—
# temp_cols = df.columns[30:40]    # 10ä¸ªæ¸©åº¦ç‚¹
# cp_cols = df.columns[40:50]      # 10ä¸ª Cp å€¼
# target_column_T1 = 'ASPEN Half Critical T'
# Tc0 = 138  # ä¸´ç•Œæ¸©åº¦å½’ä¸€åŒ–å¸¸æ•°
#
# # ========= 3. å­æ¨¡å‹è®­ç»ƒ =========
# X_groups = df[group_cols]
# valid_mask = ~df[target_column_T1].isna()
#
# poly = PolynomialFeatures(degree=2, include_bias=False)
# X_poly = poly.fit_transform(X_groups[valid_mask])
# y_exp_T1 = np.exp(df.loc[valid_mask, target_column_T1] / Tc0)
#
# T1_model = HuberRegressor(max_iter=9000).fit(X_poly, y_exp_T1)
# Cp1_model = HuberRegressor(max_iter=9000).fit(X_groups, df.iloc[:, 9])
# Cp2_model = HuberRegressor(max_iter=9000).fit(X_groups, df.iloc[:, 50])
#
# # ========= 4. æ„å»ºè®­ç»ƒæ•°æ® =========
# X_total, y_total, material_ids, temperatures = [], [], [], []
# X_poly_all = poly.transform(X_groups)
#
# for i, row in df.iterrows():
#     material_id = row.iloc[0]
#     Nk = row[group_cols].values
#     temps = row[temp_cols].values
#     cps = row[cp_cols].values
#
#     Nk_df = pd.DataFrame([Nk], columns=group_cols)
#     Nk_poly = X_poly_all[i:i+1]
#
#     try:
#         # é¢„æµ‹ T1ã€T2ã€Cp1ã€Cp2ï¼Œå¹¶è®¡ç®—æ–œç‡
#         T1_exp = T1_model.predict(Nk_poly)[0]
#         if T1_exp <= 0 or np.isnan(T1_exp):
#             continue
#         T1 = Tc0 * np.log(T1_exp)
#         T2 = T1 * 1.5
#         Cp1 = Cp1_model.predict(Nk_df)[0]
#         Cp2 = Cp2_model.predict(Nk_df)[0]
#         slope = (Cp2 - Cp1) / (T2 - T1)
#     except:
#         continue
#
#     for T, Cp in zip(temps, cps):
#         if np.isnan(T) or np.isnan(Cp):
#             continue
#
#         features = np.concatenate([
#             Nk,           # 12 ä¸ªåŸºå›¢
#             Nk * T,       # 12 ä¸ªäº¤äº’é¡¹
#             [slope * T]   # slope Ã— T
#         ])
#
#         X_total.append(features)
#         y_total.append(Cp)
#         material_ids.append(material_id)
#         temperatures.append(T)
#
# # ========= 5. æ¨¡å‹æ‹Ÿåˆï¼ˆHuberï¼‰ =========
# X_total = np.array(X_total)
# y_total = np.array(y_total)
#
# model = HuberRegressor(max_iter=10000).fit(X_total, y_total)
#
# # ========= 6. æ¨¡å‹è¯„ä¼° =========
# y_pred = model.predict(X_total)
# mse = mean_squared_error(y_total, y_pred)
# r2 = r2_score(y_total, y_pred)
# ard = np.mean(np.abs((y_total - y_pred) / y_total)) * 100
#
# print("\nğŸ“Š æ¨¡å‹è¯„ä¼°ï¼ˆå« slopeÃ—T ç‰¹å¾ï¼‰ï¼š")
# print(f"RÂ²  = {r2:.4f}")
# print(f"MSE = {mse:.2f}")
# print(f"ARD = {ard:.2f}%")
#
# # ========= 7. è¾“å‡ºé¢„æµ‹ç»“æœ =========
# results = pd.DataFrame({
#     "Material_ID": material_ids,
#     "Temperature (K)": temperatures,
#     "Cp_measured": y_total,
#     "Cp_predicted": y_pred
# })
# results.to_excel("Cpé¢„æµ‹ç»“æœ_slopeTç‰¹å¾_Î²1å›å½’.xlsx", index=False)
# print("âœ… å·²ä¿å­˜é¢„æµ‹ç»“æœä¸º: Cpé¢„æµ‹ç»“æœ_slopeTç‰¹å¾_Î²1å›å½’.xlsx")
#
# # ========= 8. è¾“å‡ºç³»æ•°è¡¨ =========
# feature_labels = (
#     list(group_cols) +               # 12 ä¸ªåŸºå›¢
#     [f"{g}_T" for g in group_cols] + # 12 ä¸ªåŸºå›¢ Ã— T
#     ["slopeÃ—T"]                      # 1 ä¸ªæ–°ç‰¹å¾
# )
#
# coefficients = pd.DataFrame({
#     "Feature": feature_labels,
#     "Contribution": model.coef_
# })
# coefficients.to_excel("Cpç³»æ•°è¡¨_slopeTç‰¹å¾_Î²1å›å½’.xlsx", index=False)
# print("ğŸ“ˆ å·²ä¿å­˜æ¨¡å‹ç³»æ•°ä¸º: Cpç³»æ•°è¡¨_slopeTç‰¹å¾_Î²1å›å½’.xlsx")
# #
# import pandas as pd
# import numpy as np
# from sklearn.linear_model import HuberRegressor
# from sklearn.preprocessing import PolynomialFeatures
# from sklearn.metrics import mean_squared_error, r2_score
#
# # ========= 1. è¯»å–æ•°æ® =========
# file_path = "heat capacity 207.xlsx"
# df = pd.read_excel(file_path, sheet_name="Sheet1")
# df = df.dropna(subset=[df.columns[0]])
# df[df.columns[0]] = df[df.columns[0]].astype(int)
#
# # ========= 2. åˆ—å®šä¹‰ =========
# group_cols = df.columns[11:30]   # 19ä¸ªåŸºå›¢åˆ—
# temp_cols = df.columns[30:40]    # 10ä¸ªæ¸©åº¦ç‚¹
# cp_cols = df.columns[40:50]      # 10ä¸ª Cp å€¼
# target_column_T1 = 'ASPEN Half Critical T'
# Tc0 = 138  # ä¸´ç•Œæ¸©åº¦å½’ä¸€åŒ–å¸¸æ•°
#
# # ========= 3. å­æ¨¡å‹è®­ç»ƒ =========
# X_groups = df[group_cols]
# valid_mask = ~df[target_column_T1].isna()
#
# poly = PolynomialFeatures(degree=2, include_bias=False)
# X_poly = poly.fit_transform(X_groups[valid_mask])
# y_exp_T1 = np.exp(df.loc[valid_mask, target_column_T1] / Tc0)
#
# # æ¨¡å‹æ‹Ÿåˆ
# T1_model = HuberRegressor(max_iter=9000).fit(X_poly, y_exp_T1)
# Cp1_model = HuberRegressor(max_iter=9000).fit(X_groups, df.iloc[:, 9])
# Cp2_model = HuberRegressor(max_iter=9000).fit(X_groups, df.iloc[:, 50])
#
# # ========= 3.1 å­æ¨¡å‹è¯„ä¼° =========
# # T1 æ¨¡å‹è¯„ä¼°
# y_pred_T1 = T1_model.predict(X_poly)
# r2_T1 = r2_score(y_exp_T1, y_pred_T1)
# mse_T1 = mean_squared_error(y_exp_T1, y_pred_T1)
#
# # Cp1 æ¨¡å‹è¯„ä¼°
# y_Cp1_true = df.iloc[:, 9]
# y_Cp1_pred = Cp1_model.predict(X_groups)
# r2_Cp1 = r2_score(y_Cp1_true, y_Cp1_pred)
# mse_Cp1 = mean_squared_error(y_Cp1_true, y_Cp1_pred)
#
# # Cp2 æ¨¡å‹è¯„ä¼°
# y_Cp2_true = df.iloc[:, 50]
# y_Cp2_pred = Cp2_model.predict(X_groups)
# r2_Cp2 = r2_score(y_Cp2_true, y_Cp2_pred)
# mse_Cp2 = mean_squared_error(y_Cp2_true, y_Cp2_pred)
#
# print("\nğŸ“Œ å­æ¨¡å‹è¯„ä¼°ç»“æœï¼š")
# print(f"T1_model ->     RÂ²: {r2_T1:.4f} | MSE: {mse_T1:.4f}")
# print(f"Cp1_model ->    RÂ²: {r2_Cp1:.4f} | MSE: {mse_Cp1:.4f}")
# print(f"Cp2_model ->    RÂ²: {r2_Cp2:.4f} | MSE: {mse_Cp2:.4f}")
#
# # ========= 4. æ„å»ºè®­ç»ƒæ•°æ® =========
# X_total, y_total, material_ids, temperatures = [], [], [], []
# X_poly_all = poly.transform(X_groups)
#
# for i, row in df.iterrows():
#     material_id = row.iloc[0]
#     Nk = row[group_cols].values
#     temps = row[temp_cols].values
#     cps = row[cp_cols].values
#
#     Nk_df = pd.DataFrame([Nk], columns=group_cols)
#     Nk_poly = X_poly_all[i:i+1]
#
#     try:
#         # é¢„æµ‹ T1ã€T2ã€Cp1ã€Cp2ï¼Œå¹¶è®¡ç®—æ–œç‡
#         T1_exp = T1_model.predict(Nk_poly)[0]
#         if T1_exp <= 0 or np.isnan(T1_exp):
#             continue
#         T1 = Tc0 * np.log(T1_exp)
#         T2 = T1 * 1.5
#         Cp1 = Cp1_model.predict(Nk_df)[0]
#         Cp2 = Cp2_model.predict(Nk_df)[0]
#         slope = (Cp2 - Cp1) / (T2 - T1)
#     except:
#         continue
#
#     for T, Cp in zip(temps, cps):
#         if np.isnan(T) or np.isnan(Cp):
#             continue
#
#         features = np.concatenate([
#             Nk,           # 19 ä¸ªåŸºå›¢
#             Nk * T,       # 19 ä¸ªäº¤äº’é¡¹
#             [slope * T]   # slope Ã— T
#         ])
#
#         X_total.append(features)
#         y_total.append(Cp)
#         material_ids.append(material_id)
#         temperatures.append(T)
#
# # ========= 5. æ¨¡å‹æ‹Ÿåˆï¼ˆHuberï¼‰ =========
# X_total = np.array(X_total)
# y_total = np.array(y_total)
#
# model = HuberRegressor(max_iter=10000).fit(X_total, y_total)
#
# # ========= 6. æ¨¡å‹è¯„ä¼° =========
# y_pred = model.predict(X_total)
# mse = mean_squared_error(y_total, y_pred)
# r2 = r2_score(y_total, y_pred)
# ard = np.mean(np.abs((y_total - y_pred) / y_total)) * 100
#
# print("\nğŸ“Š æ€»æ¨¡å‹è¯„ä¼°ï¼ˆå« slopeÃ—T ç‰¹å¾ï¼‰ï¼š")
# print(f"RÂ²  = {r2:.4f}")
# print(f"MSE = {mse:.2f}")
# print(f"ARD = {ard:.2f}%")
#
# # ========= 7. è¾“å‡ºé¢„æµ‹ç»“æœ =========
# results = pd.DataFrame({
#     "Material_ID": material_ids,
#     "Temperature (K)": temperatures,
#     "Cp_measured": y_total,
#     "Cp_predicted": y_pred
# })
# results.to_excel("Cpé¢„æµ‹ç»“æœ_slopeTç‰¹å¾_Î²1å›å½’.xlsx", index=False)
# print("âœ… å·²ä¿å­˜é¢„æµ‹ç»“æœä¸º: Cpé¢„æµ‹ç»“æœ_slopeTç‰¹å¾_Î²1å›å½’.xlsx")
#
# # ========= 8. è¾“å‡ºç³»æ•°è¡¨ =========
# feature_labels = (
#     list(group_cols) +               # 19 ä¸ªåŸºå›¢
#     [f"{g}_T" for g in group_cols] + # 19 ä¸ªåŸºå›¢ Ã— T
#     ["slopeÃ—T"]                      # 1 ä¸ªæ–°ç‰¹å¾
# )
#
# coefficients = pd.DataFrame({
#     "Feature": feature_labels,
#     "Contribution": model.coef_
# })
# coefficients.to_excel("Cpç³»æ•°è¡¨_slopeTç‰¹å¾_Î²1å›å½’.xlsx", index=False)
# print("ğŸ“ˆ å·²ä¿å­˜æ¨¡å‹ç³»æ•°ä¸º: Cpç³»æ•°è¡¨_slopeTç‰¹å¾_Î²1å›å½’.xlsx")
import pandas as pd
import numpy as np
from sklearn.linear_model import HuberRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score

# ========= 1. è¯»å–æ•°æ® =========
file_path = "heat capacity 207.xlsx"
df = pd.read_excel(file_path, sheet_name="Sheet1")
df = df.dropna(subset=[df.columns[0]])
df[df.columns[0]] = df[df.columns[0]].astype(int)

# ========= 2. åˆ—å®šä¹‰ =========
group_cols = df.columns[11:30]   # 19ä¸ªåŸºå›¢åˆ—
temp_cols = df.columns[30:40]    # 10ä¸ªæ¸©åº¦ç‚¹
cp_cols = df.columns[40:50]      # 10ä¸ª Cp å€¼
target_column_T1 = 'ASPEN Half Critical T'

# ========= 3. å­æ¨¡å‹è®­ç»ƒ =========
X_groups = df[group_cols]
valid_mask = ~df[target_column_T1].isna()

poly = PolynomialFeatures(degree=2, include_bias=False)
X_poly = poly.fit_transform(X_groups[valid_mask])

# æ”¹ç”¨ GradientBoostingRegressor é¢„æµ‹ T1
y_T1 = df.loc[valid_mask, target_column_T1].values
T1_model = GradientBoostingRegressor(
    n_estimators=300, learning_rate=0.05, max_depth=4, random_state=0
).fit(X_poly, y_T1)

# Cp1, Cp2 ä½¿ç”¨ HuberRegressor
Cp1_model = HuberRegressor(max_iter=9000).fit(X_groups, df.iloc[:, 9])
Cp2_model = HuberRegressor(max_iter=9000).fit(X_groups, df.iloc[:, 50])

# ========= 3.1 å­æ¨¡å‹è¯„ä¼° =========
y_pred_T1 = T1_model.predict(X_poly)
r2_T1 = r2_score(y_T1, y_pred_T1)
mse_T1 = mean_squared_error(y_T1, y_pred_T1)

y_Cp1_true = df.iloc[:, 9]
y_Cp1_pred = Cp1_model.predict(X_groups)
r2_Cp1 = r2_score(y_Cp1_true, y_Cp1_pred)
mse_Cp1 = mean_squared_error(y_Cp1_true, y_Cp1_pred)

y_Cp2_true = df.iloc[:, 50]
y_Cp2_pred = Cp2_model.predict(X_groups)
r2_Cp2 = r2_score(y_Cp2_true, y_Cp2_pred)
mse_Cp2 = mean_squared_error(y_Cp2_true, y_Cp2_pred)

print("\nğŸ“Œ å­æ¨¡å‹è¯„ä¼°ç»“æœï¼š")
print(f"T1_model ->     RÂ²: {r2_T1:.4f} | MSE: {mse_T1:.4f}")
print(f"Cp1_model ->    RÂ²: {r2_Cp1:.4f} | MSE: {mse_Cp1:.4f}")
print(f"Cp2_model ->    RÂ²: {r2_Cp2:.4f} | MSE: {mse_Cp2:.4f}")

# ========= 4. æ„å»ºè®­ç»ƒæ•°æ® =========
X_total, y_total, material_ids, temperatures = [], [], [], []
X_poly_all = poly.transform(X_groups)

for i, row in df.iterrows():
    material_id = row.iloc[0]
    Nk = row[group_cols].values
    temps = row[temp_cols].values
    cps = row[cp_cols].values

    Nk_df = pd.DataFrame([Nk], columns=group_cols)
    Nk_poly = X_poly_all[i:i+1]

    try:
        # æ–°æ¨¡å‹ï¼šç›´æ¥é¢„æµ‹ T1ï¼ˆæ— éœ€ log å’Œ expï¼‰
        T1 = T1_model.predict(Nk_poly)[0]
        if T1 <= 0 or np.isnan(T1):
            continue
        T2 = T1 * 1.5
        Cp1 = Cp1_model.predict(Nk_df)[0]
        Cp2 = Cp2_model.predict(Nk_df)[0]
        slope = (Cp2 - Cp1) / (T2 - T1)
        # slope = (y_Cp2_true-y_Cp1_true)/(1.5*target_column_T1-target_column_T1)
    except:
        continue

    for T, Cp in zip(temps, cps):
        if np.isnan(T) or np.isnan(Cp):
            continue

        features = np.concatenate([
            Nk,           # 19 ä¸ªåŸºå›¢
            Nk * T,       # 19 ä¸ªäº¤äº’é¡¹
            [slope * T]   # slope Ã— T
        ])

        X_total.append(features)
        y_total.append(Cp)
        material_ids.append(material_id)
        temperatures.append(T)

# ========= 5. æ¨¡å‹æ‹Ÿåˆï¼ˆHuberï¼‰ =========
X_total = np.array(X_total)
y_total = np.array(y_total)

model = HuberRegressor(max_iter=10000).fit(X_total, y_total)

# ========= 6. æ¨¡å‹è¯„ä¼° =========
y_pred = model.predict(X_total)
mse = mean_squared_error(y_total, y_pred)
r2 = r2_score(y_total, y_pred)
ard = np.mean(np.abs((y_total - y_pred) / y_total)) * 100

# === æ–°å¢è¯¯å·®ç»Ÿè®¡ ===
relative_error = np.abs((y_pred - y_total) / y_total) * 100
within_1pct = np.sum(relative_error <= 1)
within_5pct = np.sum(relative_error <= 5)
within_10pct = np.sum(relative_error <= 10)

print("\nğŸ“Š æ€»æ¨¡å‹è¯„ä¼°ï¼ˆå« slopeÃ—T ç‰¹å¾ï¼‰ï¼š")
print(f"RÂ²  = {r2:.4f}")
print(f"MSE = {mse:.2f}")
print(f"ARD = {ard:.2f}%")
print(f"âœ… è¯¯å·® â‰¤ 1% çš„æ•°æ®ç‚¹æ•°é‡: {within_1pct}")
print(f"âœ… è¯¯å·® â‰¤ 5% çš„æ•°æ®ç‚¹æ•°é‡: {within_5pct}")
print(f"âœ… è¯¯å·® â‰¤ 10% çš„æ•°æ®ç‚¹æ•°é‡: {within_10pct}")
print("\nğŸ“Š æ€»æ¨¡å‹è¯„ä¼°ï¼ˆå« slopeÃ—T ç‰¹å¾ï¼‰ï¼š")
print(f"RÂ²  = {r2:.4f}")
print(f"MSE = {mse:.2f}")
print(f"ARD = {ard:.2f}%")

# ========= 7. è¾“å‡ºé¢„æµ‹ç»“æœ =========
results = pd.DataFrame({
    "Material_ID": material_ids,
    "Temperature (K)": temperatures,
    "Cp_measured": y_total,
    "Cp_predicted": y_pred
})
results.to_excel("Cpé¢„æµ‹ç»“æœ_slopeTç‰¹å¾_Î²1å›å½’.xlsx", index=False)
print("âœ… å·²ä¿å­˜é¢„æµ‹ç»“æœä¸º: Cpé¢„æµ‹ç»“æœ_slopeTç‰¹å¾_Î²1å›å½’.xlsx")

# ========= 8. è¾“å‡ºç³»æ•°è¡¨ =========
feature_labels = (
    list(group_cols) +               # 19 ä¸ªåŸºå›¢
    [f"{g}_T" for g in group_cols] + # 19 ä¸ªåŸºå›¢ Ã— T
    ["slopeÃ—T"]                      # 1 ä¸ªæ–°ç‰¹å¾
)

coefficients = pd.DataFrame({
    "Feature": feature_labels,
    "Contribution": model.coef_
})
coefficients.to_excel("Cpç³»æ•°è¡¨_slopeTç‰¹å¾_Î²1å›å½’.xlsx", index=False)
print("ğŸ“ˆ å·²ä¿å­˜æ¨¡å‹ç³»æ•°ä¸º: Cpç³»æ•°è¡¨_slopeTç‰¹å¾_Î²1å›å½’.xlsx")
