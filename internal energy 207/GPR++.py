# import pandas as pd
# import numpy as np
# from sklearn.linear_model import HuberRegressor
# from sklearn.metrics import mean_squared_error, r2_score
# from sklearn.preprocessing import PolynomialFeatures, StandardScaler
# from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
#
# # ==== 1. è¯»å–ä¸»æ•°æ®è¡¨ï¼ˆåŒ…å«åŸºå›¢å’Œç‰©è´¨ IDï¼‰ ====
# df = pd.read_excel("internal energy 207.xlsx", sheet_name="Sheet1")
# material_ids = df.iloc[:, 0].values  # å‡è®¾ç¬¬ä¸€åˆ—æ˜¯ Material_ID
# Nk_all = df.iloc[:, 13:32].apply(pd.to_numeric, errors='coerce')  # ç¬¬14~32åˆ—ä¸ºåŸºå›¢
#
# # ==== 2. å®šä¹‰åˆ—ç´¢å¼• ====
# group_cols = df.columns[13:32]  # ç¬¬14~32åˆ—ï¼šåŸºå›¢
# temp_cols = df.columns[32:42]   # ç¬¬33~42åˆ—ï¼šæ¸©åº¦
# hvap_cols = df.columns[42:52]   # ç¬¬43~52åˆ—ï¼šç›®æ ‡å˜é‡ Hvap
#
# # ==== 3. è¯»å–å¹¶è®­ç»ƒ HVap_Tb æ¨¡å‹ ====
# df_Tb = pd.read_excel("selected_25_descriptors_boiling.xlsx")
# X_Tb = df_Tb.drop(columns=["internal energy at boiling temperature"])
# rf_Tb = RandomForestRegressor(random_state=42).fit(X_Tb, df_Tb["internal energy at boiling temperature"])
# HVap_Tb_all = rf_Tb.predict(X_Tb)
#
# # ==== 4. æ‹Ÿåˆ Tb æ¨¡å‹ ====
# Tb_raw = df.iloc[:, 5].values  # åŸå§‹ Tb åˆ—
# Tb0 = 222.543
# poly = PolynomialFeatures(degree=2, include_bias=False)
# Nk_poly = poly.fit_transform(Nk_all)
# mask_tb = ~np.isnan(Tb_raw)
#
# model_Tb = HuberRegressor(max_iter=10000).fit(Nk_poly[mask_tb], np.exp(Tb_raw[mask_tb] / Tb0))
# Tb_pred_all = Tb0 * np.log(np.clip(model_Tb.predict(Nk_poly), 1e-6, None))  # æ‰€æœ‰ç‰©è´¨çš„å‚è€ƒæ¸©åº¦é¢„æµ‹
#
# # ==== 5. A_k ç³»æ•°è®­ç»ƒ ====
# G = Nk_all.values  # (n, 19) åŸå§‹åŸºå›¢æ•°æ®
# X_rows, y_rows = [], []
# temp_eval = []  # ä¿å­˜æ¸©åº¦ç‚¹ä¿¡æ¯ç”¨äºè¯„ä¼°
#
# # æ„å»ºè®­ç»ƒé›†
# for i in range(len(df)):  # éå†æ‰€æœ‰ç‰©è´¨
#     for j, (tcol, hvcol) in enumerate(zip(temp_cols, hvap_cols)):
#         Tj = df.at[i, tcol]  # æ¸©åº¦å€¼
#         Hvapj = df.at[i, hvcol]  # ç›®æ ‡å˜é‡å€¼
#
#         if np.isnan(Tj) or np.isnan(Hvapj):
#             continue
#
#         Tb_i = Tb_pred_all[i]  # ç‰©è´¨içš„å‚è€ƒæ¸©åº¦
#         HVap_Tb_i = HVap_Tb_all[i]  # ç‰©è´¨içš„å‚è€ƒç›®æ ‡å˜é‡å€¼
#
#         # ç‰¹å¾ï¼š(T - T_ref) Ã— G (ä½¿ç”¨åŸå§‹19ä¸ªåŸºå›¢)
#         Xj = (Tj - Tb_i) * G[i]  # å½¢çŠ¶: (19,)
#
#         # ç›®æ ‡ï¼šHvap - Hvap_ref
#         yj = Hvapj - HVap_Tb_i
#
#         X_rows.append(Xj)
#         y_rows.append(yj)
#         temp_eval.append((tcol, hvcol, i, j))
#
# X_A = np.array(X_rows)  # (n_samples, 19)
# y_A = np.array(y_rows)  # (n_samples,)
#
# # è®­ç»ƒ A_k ç³»æ•°æ¨¡å‹
# A_solver = HuberRegressor(fit_intercept=False, max_iter=5000)
# A_solver.fit(X_A, y_A)
# A_vec = A_solver.coef_  # é•¿åº¦19ï¼Œå¯¹åº”19ä¸ªåŸºå›¢
#
# # ==== 6. ç”ŸæˆåŸºå‡†é¢„æµ‹ ====
# HVap_pred_baseline = pd.DataFrame(index=df.index, columns=hvap_cols, dtype=float)
#
# for i in range(len(df)):  # éå†æ‰€æœ‰ç‰©è´¨
#     Tb_i = Tb_pred_all[i]  # ç‰©è´¨içš„å‚è€ƒæ¸©åº¦
#     HVap_Tb_i = HVap_Tb_all[i]  # ç‰©è´¨içš„å‚è€ƒç›®æ ‡å˜é‡å€¼
#
#     for j, (tcol, hvcol) in enumerate(zip(temp_cols, hvap_cols)):
#         Tj = df.at[i, tcol]  # æ¸©åº¦å€¼
#
#         if np.isnan(Tj):
#             HVap_pred_baseline.at[i, hvcol] = np.nan
#             continue
#
#         # ç‰¹å¾ï¼š(T - T_ref) Ã— G (ä½¿ç”¨åŸå§‹19ä¸ªåŸºå›¢)
#         Xj = (Tj - Tb_i) * G[i]
#
#         # é¢„æµ‹ï¼šHvap_ref + A_k Ã— (T - T_ref) Ã— G
#         HVap_pred_j = HVap_Tb_i + Xj @ A_vec
#         HVap_pred_baseline.at[i, hvcol] = HVap_pred_j
#
# # ==== 7. æ„å»ºæ®‹å·®è®­ç»ƒé›† ====
# residual_features = []
# residual_targets = []
# sample_info = []  # ä¿å­˜æ ·æœ¬ä¿¡æ¯ç”¨äºè¿½è¸ª
#
# for tcol, hvcol in zip(temp_cols, hvap_cols):
#     Tj = df[tcol].to_numpy()
#     Hvapj = df[hvcol].to_numpy()
#     msk = (~np.isnan(Tj)) & (~np.isnan(Hvapj))
#
#     for i in np.where(msk)[0]:
#         # åŸºç¡€ç‰¹å¾ï¼šåŸºå›¢ç»„æˆ
#         base_features = list(G[i])
#
#         # æ¸©åº¦ç›¸å…³ç‰¹å¾
#         temp_features = [
#             Tj[i],  # ç»å¯¹æ¸©åº¦
#             Tj[i] - Tb_pred_all[i],  # ç›¸å¯¹äºå‚è€ƒæ¸©åº¦çš„å·®å€¼
#             Tj[i] / Tb_pred_all[i] if Tb_pred_all[i] > 0 else 0,  # ç›¸å¯¹æ¸©åº¦
#             np.log(Tj[i]) if Tj[i] > 0 else 0,  # æ¸©åº¦å¯¹æ•°
#         ]
#
#         # åŸºå‡†é¢„æµ‹å€¼ä½œä¸ºç‰¹å¾
#         baseline_pred = HVap_pred_baseline.at[i, hvcol]
#         baseline_features = [baseline_pred]
#
#         # å‚è€ƒå€¼ç‰¹å¾
#         ref_features = [
#             Tb_pred_all[i],  # å‚è€ƒæ¸©åº¦
#             HVap_Tb_all[i],  # å‚è€ƒæ±½åŒ–ç„“
#         ]
#
#         # ç»„åˆæ‰€æœ‰ç‰¹å¾
#         all_features = base_features + temp_features + baseline_features + ref_features
#         residual_features.append(all_features)
#
#         # æ®‹å·®ç›®æ ‡ï¼šå®é™…å€¼ - åŸºå‡†é¢„æµ‹å€¼
#         residual = Hvapj[i] - baseline_pred
#         residual_targets.append(residual)
#
#         sample_info.append((i, tcol, hvcol))
#
# residual_features = np.array(residual_features)
# residual_targets = np.array(residual_targets)
#
# # æ ‡å‡†åŒ–ç‰¹å¾
# scaler = StandardScaler()
# residual_features_scaled = scaler.fit_transform(residual_features)
#
# # è®­ç»ƒæ®‹å·®æ¨¡å‹ï¼ˆä½¿ç”¨æ¢¯åº¦æå‡å›å½’ï¼‰
# residual_model = GradientBoostingRegressor(
#     n_estimators=200,
#     learning_rate=0.05,
#     max_depth=5,
#     min_samples_split=20,
#     min_samples_leaf=10,
#     random_state=42
# )
#
# # è®­ç»ƒæ®‹å·®æ¨¡å‹
# residual_model.fit(residual_features_scaled, residual_targets)
#
# # ==== 8. ç”Ÿæˆæœ€ç»ˆé¢„æµ‹ï¼ˆåŸºå‡† + æ®‹å·®ä¿®æ­£ï¼‰ ====
# HVap_pred_final = pd.DataFrame(index=df.index, columns=hvap_cols, dtype=float)
#
# for tcol, hvcol in zip(temp_cols, hvap_cols):
#     Tj = df[tcol].to_numpy()
#
#     # ä¸ºæ‰€æœ‰æ ·æœ¬æ„å»ºç‰¹å¾
#     features_list = []
#     valid_indices = []
#
#     for i in range(len(df)):
#         if np.isnan(Tj[i]):
#             continue
#
#         # æ„å»ºä¸è®­ç»ƒæ—¶ç›¸åŒçš„ç‰¹å¾
#         base_features = list(G[i])
#         temp_features = [
#             Tj[i],
#             Tj[i] - Tb_pred_all[i],
#             Tj[i] / Tb_pred_all[i] if Tb_pred_all[i] > 0 else 0,
#             np.log(Tj[i]) if Tj[i] > 0 else 0,
#         ]
#         baseline_pred = HVap_pred_baseline.at[i, hvcol]
#         baseline_features = [baseline_pred]
#         ref_features = [Tb_pred_all[i], HVap_Tb_all[i]]
#
#         all_features = base_features + temp_features + baseline_features + ref_features
#         features_list.append(all_features)
#         valid_indices.append(i)
#
#     if features_list:
#         features_array = np.array(features_list)
#         features_scaled = scaler.transform(features_array)
#
#         # é¢„æµ‹æ®‹å·®
#         residual_pred = residual_model.predict(features_scaled)
#
#         # æœ€ç»ˆé¢„æµ‹ = åŸºå‡†é¢„æµ‹ + æ®‹å·®ä¿®æ­£
#         for idx, residual_val in zip(valid_indices, residual_pred):
#             final_pred = HVap_pred_baseline.at[idx, hvcol] + residual_val
#             HVap_pred_final.at[idx, hvcol] = final_pred
#
#     # å¯¹äºæ— æ•ˆæ¸©åº¦ç‚¹ï¼Œä¿æŒNaN
#     HVap_pred_final[hvcol] = np.where(np.isnan(Tj), np.nan, HVap_pred_final[hvcol])
#
# # ==== 9. è¯„ä¼°æ¨¡å‹æ€§èƒ½ ====
# # åŸºå‡†æ¨¡å‹è¯„ä¼°
# print("\n=== åŸºå‡†æ¨¡å‹æ€§èƒ½ ===")
# y_true_all, y_pred_baseline = [], []
# for hvcol in hvap_cols:
#     m = (~df[hvcol].isna()) & (~HVap_pred_baseline[hvcol].isna())
#     if m.any():
#         y_true_all.append(df.loc[m, hvcol].to_numpy())
#         y_pred_baseline.append(HVap_pred_baseline.loc[m, hvcol].to_numpy())
#
# y_true_all = np.concatenate(y_true_all)
# y_pred_baseline = np.concatenate(y_pred_baseline)
#
# mse_baseline = mean_squared_error(y_true_all, y_pred_baseline)
# r2_baseline = r2_score(y_true_all, y_pred_baseline)
# print(f"åŸºå‡†æ¨¡å‹ - MSE: {mse_baseline:.6f}, RÂ²: {r2_baseline:.6f}")
#
# # æœ€ç»ˆæ¨¡å‹è¯„ä¼°
# print("\n=== æœ€ç»ˆæ¨¡å‹æ€§èƒ½ï¼ˆåŸºå‡† + æ®‹å·®ä¿®æ­£ï¼‰===")
# y_true_all, y_pred_final = [], []
# for hvcol in hvap_cols:
#     m = (~df[hvcol].isna()) & (~HVap_pred_final[hvcol].isna())
#     if m.any():
#         y_true_all.append(df.loc[m, hvcol].to_numpy())
#         y_pred_final.append(HVap_pred_final.loc[m, hvcol].to_numpy())
#
# y_true_all = np.concatenate(y_true_all)
# y_pred_final = np.concatenate(y_pred_final)
#
# mse_final = mean_squared_error(y_true_all, y_pred_final)
# r2_final = r2_score(y_true_all, y_pred_final)
# print(f"æœ€ç»ˆæ¨¡å‹ - MSE: {mse_final:.6f}, RÂ²: {r2_final:.6f}")
#
# # æ”¹è¿›ç¨‹åº¦
# improvement = r2_final - r2_baseline
# print(f"\næ”¹è¿›ç¨‹åº¦: RÂ² æå‡äº† {improvement:.4f} ({improvement / r2_baseline * 100:.2f}%)")
#
# # ==== åˆ†æ¸©åº¦ç‚¹è¯„ä¼° ====
# print("\nåˆ†æ¸©åº¦ç‚¹è¯„ä¼°:")
# for tcol, hvcol in zip(temp_cols, hvap_cols):
#     m = (~df[tcol].isna()) & (~df[hvcol].isna()) & (~HVap_pred_final[hvcol].isna())
#     if m.any():
#         hvap_true = df.loc[m, hvcol].to_numpy()
#         hvap_pred = HVap_pred_final.loc[m, hvcol].to_numpy()
#         mse_temp = mean_squared_error(hvap_true, hvap_pred)
#         r2_temp = r2_score(hvap_true, hvap_pred)
#         print(f"  {tcol}: MSE = {mse_temp:.6f}, R2 = {r2_temp:.6f}")
#
# # ==== ä¿å­˜æœ€ç»ˆçš„ç»“æœ ====
# id_col = df.columns[0]  # ç‰©è´¨ID/åç§°æ‰€åœ¨åˆ—
# out_path = "hvap_actual_vs_pred_with_residual_correction.xlsx"
#
# rows = []
# for idx, _ in df.iterrows():
#     ID = df.at[idx, id_col]
#     for j, (tcol, hvcol) in enumerate(zip(temp_cols, hvap_cols), start=1):
#         T = df.at[idx, tcol]
#         HVap_act = df.at[idx, hvcol]
#         HVap_base = HVap_pred_baseline.at[idx, hvcol] if pd.notna(HVap_pred_baseline.at[idx, hvcol]) else np.nan
#         HVap_final = HVap_pred_final.at[idx, hvcol] if pd.notna(HVap_pred_final.at[idx, hvcol]) else np.nan
#
#         # è®¡ç®—è¯¯å·®
#         err_base = (HVap_base - HVap_act) if (pd.notna(HVap_base) and pd.notna(HVap_act)) else np.nan
#         err_final = (HVap_final - HVap_act) if (pd.notna(HVap_final) and pd.notna(HVap_act)) else np.nan
#         residual_correction = (HVap_final - HVap_base) if (pd.notna(HVap_final) and pd.notna(HVap_base)) else np.nan
#
#         rows.append({
#             id_col: ID,
#             "temp_index": j,
#             "temp_col": tcol,
#             "T": T,
#             "HVap_actual": HVap_act,
#             "HVap_baseline": HVap_base,
#             "HVap_final": HVap_final,
#             "error_baseline": err_base,
#             "error_final": err_final,
#             "residual_correction": residual_correction,
#             "T_ref": Tb_pred_all[idx],
#             "HVap_ref": HVap_Tb_all[idx]
#         })
#
# long_compare = pd.DataFrame(rows).sort_values([id_col, "temp_index"])
#
# with pd.ExcelWriter(out_path, engine="xlsxwriter") as writer:
#     long_compare.to_excel(writer, sheet_name="compare_long", index=False)
#
# print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {out_path}")


import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import HuberRegressor
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import cross_val_score

# ==== 1. è¯»å–ä¸»æ•°æ®è¡¨ï¼ˆåŒ…å«åŸºå›¢å’Œç‰©è´¨ IDï¼‰ ====
df = pd.read_excel("internal energy 207.xlsx", sheet_name="Sheet1")
material_ids = df.iloc[:, 0].values  # å‡è®¾ç¬¬ä¸€åˆ—æ˜¯ Material_ID
Nk_all = df.iloc[:, 13:32].apply(pd.to_numeric, errors='coerce')  # ç¬¬14~32åˆ—ä¸ºåŸºå›¢

# ==== 2. å®šä¹‰åˆ—ç´¢å¼• ====
group_cols = df.columns[13:32]  # ç¬¬14~32åˆ—ï¼šåŸºå›¢
temp_cols = df.columns[32:42]  # ç¬¬33~42åˆ—ï¼šæ¸©åº¦
hvap_cols = df.columns[42:52]  # ç¬¬43~52åˆ—ï¼šç›®æ ‡å˜é‡ Hvap

# ==== 3. è¯»å–å¹¶è®­ç»ƒ HVap_Tb æ¨¡å‹ ====
df_Tb = pd.read_excel("selected_25_descriptors_boiling.xlsx")
X_Tb = df_Tb.drop(columns=["internal energy at boiling temperature"])
rf_Tb = RandomForestRegressor(random_state=42).fit(X_Tb, df_Tb["internal energy at boiling temperature"])
HVap_Tb_all = rf_Tb.predict(X_Tb)

# ==== 4. æ‹Ÿåˆ Tb æ¨¡å‹ ====
Tb_raw = df.iloc[:, 5].values  # åŸå§‹ Tb åˆ—
Tb0 = 222.543
poly = PolynomialFeatures(degree=2, include_bias=False)
Nk_poly = poly.fit_transform(Nk_all)
mask_tb = ~np.isnan(Tb_raw)

model_Tb = HuberRegressor(max_iter=10000).fit(Nk_poly[mask_tb], np.exp(Tb_raw[mask_tb] / Tb0))
Tb_pred_all = Tb0 * np.log(np.clip(model_Tb.predict(Nk_poly), 1e-6, None))

# ==== 5. A_k ç³»æ•°è®­ç»ƒ ====
# ä½¿ç”¨åŸå§‹19ä¸ªåŸºå›¢ï¼ˆä¸æ˜¯æ‰©å±•åçš„ï¼‰
G = Nk_all.values  # (n, 19) åŸå§‹åŸºå›¢æ•°æ®
X_rows, y_rows = [], []
temp_eval = []  # ä¿å­˜æ¸©åº¦ç‚¹ä¿¡æ¯ç”¨äºè¯„ä¼°

# æ„å»ºè®­ç»ƒé›†
for i in range(len(df)):  # éå†æ‰€æœ‰ç‰©è´¨
    for j, (tcol, hvcol) in enumerate(zip(temp_cols, hvap_cols)):
        Tj = df.at[i, tcol]  # æ¸©åº¦å€¼
        Hvapj = df.at[i, hvcol]  # ç›®æ ‡å˜é‡å€¼

        # è·³è¿‡NaNå€¼
        if np.isnan(Tj) or np.isnan(Hvapj):
            continue

        Tb_i = Tb_pred_all[i]  # ç‰©è´¨içš„å‚è€ƒæ¸©åº¦
        HVap_Tb_i = HVap_Tb_all[i]  # ç‰©è´¨içš„å‚è€ƒç›®æ ‡å˜é‡å€¼

        # ç‰¹å¾ï¼š(T - T_ref) Ã— G (ä½¿ç”¨åŸå§‹19ä¸ªåŸºå›¢)
        Xj = (Tj - Tb_i) * G[i]  # å½¢çŠ¶: (19,)

        # ç›®æ ‡ï¼šHvap - Hvap_ref
        yj = Hvapj - HVap_Tb_i

        X_rows.append(Xj)
        y_rows.append(yj)
        temp_eval.append((tcol, hvcol, i, j))

X_A = np.array(X_rows)  # (n_samples, 19)
y_A = np.array(y_rows)  # (n_samples,)

# è®­ç»ƒ A_k ç³»æ•°æ¨¡å‹
A_solver = HuberRegressor(fit_intercept=False, max_iter=5000)
A_solver.fit(X_A, y_A)
A_vec = A_solver.coef_  # é•¿åº¦19ï¼Œå¯¹åº”19ä¸ªåŸºå›¢

# ==== 6. ç”ŸæˆåŸºå‡†é¢„æµ‹ ====
HVap_pred_baseline = pd.DataFrame(index=df.index, columns=hvap_cols, dtype=float)

for i in range(len(df)):  # éå†æ‰€æœ‰ç‰©è´¨
    Tb_i = Tb_pred_all[i]  # ç‰©è´¨içš„å‚è€ƒæ¸©åº¦
    HVap_Tb_i = HVap_Tb_all[i]  # ç‰©è´¨içš„å‚è€ƒç›®æ ‡å˜é‡å€¼

    for j, (tcol, hvcol) in enumerate(zip(temp_cols, hvap_cols)):
        Tj = df.at[i, tcol]  # æ¸©åº¦å€¼

        if np.isnan(Tj):
            HVap_pred_baseline.at[i, hvcol] = np.nan
            continue

        # ç‰¹å¾ï¼š(T - T_ref) Ã— G (ä½¿ç”¨åŸå§‹19ä¸ªåŸºå›¢)
        Xj = (Tj - Tb_i) * G[i]

        # é¢„æµ‹ï¼šHvap_ref + A_k Ã— (T - T_ref) Ã— G
        HVap_pred_j = HVap_Tb_i + Xj @ A_vec
        HVap_pred_baseline.at[i, hvcol] = HVap_pred_j

# ==== 7. æ®‹å·®æœºå™¨å­¦ä¹ æ¨¡å‹ ====
print("è®­ç»ƒæ®‹å·®æœºå™¨å­¦ä¹ æ¨¡å‹...")

# æ„å»ºæ®‹å·®è®­ç»ƒæ•°æ®é›†
residual_features = []
residual_targets = []
sample_info = []  # ä¿å­˜æ ·æœ¬ä¿¡æ¯ç”¨äºè¿½è¸ª

for tcol, hvcol in zip(temp_cols, hvap_cols):
    Tj = df[tcol].to_numpy()
    Hvapj = df[hvcol].to_numpy()
    msk = (~np.isnan(Tj)) & (~np.isnan(Hvapj))

    for i in np.where(msk)[0]:
        # åŸºç¡€ç‰¹å¾ï¼šåŸºå›¢ç»„æˆ
        base_features = list(G[i])

        # æ¸©åº¦ç›¸å…³ç‰¹å¾
        temp_features = [
            Tj[i],  # ç»å¯¹æ¸©åº¦
            Tj[i] - Tb_pred_all[i],  # ç›¸å¯¹äºå‚è€ƒæ¸©åº¦çš„å·®å€¼
            Tj[i] / Tb_pred_all[i] if Tb_pred_all[i] > 0 else 0,  # ç›¸å¯¹æ¸©åº¦
            np.log(Tj[i]) if Tj[i] > 0 else 0,  # æ¸©åº¦å¯¹æ•°
        ]

        # åŸºå‡†é¢„æµ‹å€¼ä½œä¸ºç‰¹å¾
        baseline_pred = HVap_pred_baseline.at[i, hvcol]
        baseline_features = [baseline_pred]

        # å‚è€ƒå€¼ç‰¹å¾
        ref_features = [
            Tb_pred_all[i],  # å‚è€ƒæ¸©åº¦
            HVap_Tb_all[i],  # å‚è€ƒå†…èƒ½å€¼
        ]

        # ç»„åˆæ‰€æœ‰ç‰¹å¾
        all_features = base_features + temp_features + baseline_features + ref_features
        residual_features.append(all_features)

        # æ®‹å·®ç›®æ ‡ï¼šå®é™…å€¼ - åŸºå‡†é¢„æµ‹å€¼
        residual = Hvapj[i] - baseline_pred
        residual_targets.append(residual)

        sample_info.append((i, tcol, hvcol))

residual_features = np.array(residual_features)
residual_targets = np.array(residual_targets)

print(f"æ®‹å·®è®­ç»ƒé›†å½¢çŠ¶: {residual_features.shape}")
print(f"æ®‹å·®ç›®æ ‡å½¢çŠ¶: {residual_targets.shape}")

# æ ‡å‡†åŒ–ç‰¹å¾
scaler = StandardScaler()
residual_features_scaled = scaler.fit_transform(residual_features)

# è®­ç»ƒæ®‹å·®æ¨¡å‹ï¼ˆä½¿ç”¨æ¢¯åº¦æå‡å›å½’ï¼‰
residual_model = GradientBoostingRegressor(
    n_estimators=200,
    learning_rate=0.05,
    max_depth=5,
    min_samples_split=20,
    min_samples_leaf=10,
    random_state=42
)

# äº¤å‰éªŒè¯è¯„ä¼°æ®‹å·®æ¨¡å‹
cv_scores = cross_val_score(residual_model, residual_features_scaled, residual_targets,
                            cv=5, scoring='r2')
print(f"æ®‹å·®æ¨¡å‹äº¤å‰éªŒè¯ RÂ²: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")

# è®­ç»ƒæœ€ç»ˆæ®‹å·®æ¨¡å‹
residual_model.fit(residual_features_scaled, residual_targets)

# ==== 8. ç”Ÿæˆæœ€ç»ˆé¢„æµ‹ï¼ˆåŸºå‡† + æ®‹å·®ä¿®æ­£ï¼‰ ====
HVap_pred_final = pd.DataFrame(index=df.index, columns=hvap_cols, dtype=float)

for tcol, hvcol in zip(temp_cols, hvap_cols):
    Tj = df[tcol].to_numpy()

    # ä¸ºæ‰€æœ‰æ ·æœ¬æ„å»ºç‰¹å¾
    features_list = []
    valid_indices = []

    for i in range(len(df)):
        if np.isnan(Tj[i]):
            continue

        # æ„å»ºä¸è®­ç»ƒæ—¶ç›¸åŒçš„ç‰¹å¾
        base_features = list(G[i])
        temp_features = [
            Tj[i],
            Tj[i] - Tb_pred_all[i],
            Tj[i] / Tb_pred_all[i] if Tb_pred_all[i] > 0 else 0,
            np.log(Tj[i]) if Tj[i] > 0 else 0,
        ]
        baseline_pred = HVap_pred_baseline.at[i, hvcol]
        baseline_features = [baseline_pred]
        ref_features = [Tb_pred_all[i], HVap_Tb_all[i]]

        all_features = base_features + temp_features + baseline_features + ref_features
        features_list.append(all_features)
        valid_indices.append(i)

    if features_list:
        features_array = np.array(features_list)
        features_scaled = scaler.transform(features_array)

        # é¢„æµ‹æ®‹å·®
        residual_pred = residual_model.predict(features_scaled)

        # æœ€ç»ˆé¢„æµ‹ = åŸºå‡†é¢„æµ‹ + æ®‹å·®ä¿®æ­£
        for idx, residual_val in zip(valid_indices, residual_pred):
            final_pred = HVap_pred_baseline.at[idx, hvcol] + residual_val
            HVap_pred_final.at[idx, hvcol] = final_pred

    # å¯¹äºæ— æ•ˆæ¸©åº¦ç‚¹ï¼Œä¿æŒNaN
    HVap_pred_final[hvcol] = np.where(np.isnan(Tj), np.nan, HVap_pred_final[hvcol])

# ==== 9. è¯„ä¼°æ¨¡å‹æ€§èƒ½ ====
# åŸºå‡†æ¨¡å‹è¯„ä¼°
print("\n=== åŸºå‡†æ¨¡å‹æ€§èƒ½ ===")
y_true_all, y_pred_baseline = [], []
for hvcol in hvap_cols:
    m = (~df[hvcol].isna()) & (~HVap_pred_baseline[hvcol].isna())
    if m.any():
        y_true_all.append(df.loc[m, hvcol].to_numpy())
        y_pred_baseline.append(HVap_pred_baseline.loc[m, hvcol].to_numpy())

y_true_all = np.concatenate(y_true_all)
y_pred_baseline = np.concatenate(y_pred_baseline)

mse_baseline = mean_squared_error(y_true_all, y_pred_baseline)
r2_baseline = r2_score(y_true_all, y_pred_baseline)
print(f"åŸºå‡†æ¨¡å‹ - MSE: {mse_baseline:.6f}, RÂ²: {r2_baseline:.6f}")

# æœ€ç»ˆæ¨¡å‹è¯„ä¼°
print("\n=== æœ€ç»ˆæ¨¡å‹æ€§èƒ½ï¼ˆåŸºå‡† + æ®‹å·®ä¿®æ­£ï¼‰===")
y_true_all, y_pred_final = [], []
for hvcol in hvap_cols:
    m = (~df[hvcol].isna()) & (~HVap_pred_final[hvcol].isna())
    if m.any():
        y_true_all.append(df.loc[m, hvcol].to_numpy())
        y_pred_final.append(HVap_pred_final.loc[m, hvcol].to_numpy())

y_true_all = np.concatenate(y_true_all)
y_pred_final = np.concatenate(y_pred_final)

mse_final = mean_squared_error(y_true_all, y_pred_final)
r2_final = r2_score(y_true_all, y_pred_final)
print(f"æœ€ç»ˆæ¨¡å‹ - MSE: {mse_final:.6f}, RÂ²: {r2_final:.6f}")

# æ”¹è¿›ç¨‹åº¦
improvement = r2_final - r2_baseline
print(f"\næ”¹è¿›ç¨‹åº¦: RÂ² æå‡äº† {improvement:.4f} ({improvement / r2_baseline * 100:.2f}%)")

# ==== 10. åˆ†æ¸©åº¦ç‚¹è¯„ä¼° ====
print("\nåˆ†æ¸©åº¦ç‚¹è¯„ä¼°:")
for tcol, hvcol in zip(temp_cols, hvap_cols):
    m = (~df[tcol].isna()) & (~df[hvcol].isna()) & (~HVap_pred_final[hvcol].isna())
    if m.any():
        hvap_true = df.loc[m, hvcol].to_numpy()
        hvap_pred = HVap_pred_final.loc[m, hvcol].to_numpy()
        mse_temp = mean_squared_error(hvap_true, hvap_pred)
        r2_temp = r2_score(hvap_true, hvap_pred)
        print(f"  {tcol}: MSE = {mse_temp:.6f}, R2 = {r2_temp:.6f}")

# ==== 11. ä¿å­˜ç»“æœ ====
id_col = df.columns[0]  # ç‰©è´¨ID/åç§°æ‰€åœ¨åˆ—
out_path = "internal_energy_actual_vs_pred_with_residual_correction.xlsx"

rows = []
for idx, _ in df.iterrows():
    ID = df.at[idx, id_col]
    for j, (tcol, hvcol) in enumerate(zip(temp_cols, hvap_cols), start=1):
        T = df.at[idx, tcol]
        HVap_act = df.at[idx, hvcol]
        HVap_base = HVap_pred_baseline.at[idx, hvcol] if pd.notna(HVap_pred_baseline.at[idx, hvcol]) else np.nan
        HVap_final = HVap_pred_final.at[idx, hvcol] if pd.notna(HVap_pred_final.at[idx, hvcol]) else np.nan

        # è®¡ç®—è¯¯å·®
        err_base = (HVap_base - HVap_act) if (pd.notna(HVap_base) and pd.notna(HVap_act)) else np.nan
        err_final = (HVap_final - HVap_act) if (pd.notna(HVap_final) and pd.notna(HVap_act)) else np.nan
        residual_correction = (HVap_final - HVap_base) if (pd.notna(HVap_final) and pd.notna(HVap_base)) else np.nan

        rows.append({
            id_col: ID,
            "temp_index": j,
            "temp_col": tcol,
            "T": T,
            "HVap_actual": HVap_act,
            "HVap_baseline": HVap_base,
            "HVap_final": HVap_final,
            "error_baseline": err_base,
            "error_final": err_final,
            "residual_correction": residual_correction,
            "T_ref": Tb_pred_all[idx],
            "HVap_ref": HVap_Tb_all[idx]
        })

long_compare = pd.DataFrame(rows).sort_values([id_col, "temp_index"])

with pd.ExcelWriter(out_path, engine="xlsxwriter") as writer:
    long_compare.to_excel(writer, sheet_name="compare_long", index=False)

print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {out_path}")
# â€”â€” ç®€æ´ç›¸å¯¹è¯¯å·®ç»Ÿè®¡ï¼ˆæœ€ç»ˆï¼‰â€”â€”
relative_error_final = np.abs((y_pred_final - y_true_all) / y_true_all) * 100
within_1pct_final  = np.sum(relative_error_final <= 1)
within_5pct_final  = np.sum(relative_error_final <= 5)
within_10pct_final = np.sum(relative_error_final <= 10)
ard_final = np.mean(relative_error_final)

print("\nğŸ“Š æ€»æ¨¡å‹è¯„ä¼°ï¼ˆåŸºå‡† + æ®‹å·®ä¿®æ­£ï¼‰ï¼š")
print(f"RÂ²  = {r2_final:.4f}")
print(f"MSE = {mse_final:.6f}")
print(f"ARD = {ard_final:.2f}%")
print(f"âœ… è¯¯å·® â‰¤ 1% çš„æ•°æ®ç‚¹æ•°é‡: {within_1pct_final}")
print(f"âœ… è¯¯å·® â‰¤ 5% çš„æ•°æ®ç‚¹æ•°é‡: {within_5pct_final}")
print(f"âœ… è¯¯å·® â‰¤ 10% çš„æ•°æ®ç‚¹æ•°é‡: {within_10pct_final}")
