#
# import pandas as pd
# import numpy as np
# from sklearn.ensemble import RandomForestRegressor
# from sklearn.metrics import mean_squared_error, r2_score
#
# # ==== 1. è¯»å–æ•°æ® ====
# df = pd.read_excel("volume208.xlsx", sheet_name="Sheet1")
#
# # ==== 2. å®šä¹‰åˆ— ====
# group_cols = df.columns[13:32]   # ç¬¬14~25åˆ—ï¼šåŸºå›¢
# temp_cols = df.columns[32:42]    # ç¬¬26~35åˆ—ï¼šæ¸©åº¦
# hvap_cols = df.columns[42:52]    # ç¬¬36~45åˆ—ï¼šHvap
#
# # ==== 3. å‡†å¤‡ slope æ‰€éœ€æ¨¡å‹è¾“å…¥ ====
# df_298 = pd.read_excel("selected_25_descriptors_normal.xlsx")
# X_298 = df_298.drop(columns=["volume at normal temperature"])
# rf_298 = RandomForestRegressor(random_state=42).fit(X_298, df_298["volume at normal temperature"])
# HVap_298_all = rf_298.predict(X_298)
#
# df_Tb = pd.read_excel("selected_25_descriptors_boiling.xlsx")
# X_Tb = df_Tb.drop(columns=["volume at boiling temperature"])
# rf_Tb = RandomForestRegressor(random_state=42).fit(X_Tb, df_Tb["volume at boiling temperature"])
# HVap_Tb_all = rf_Tb.predict(X_Tb)
#
# # ==== 4. Tb æ¨¡å‹é¢„æµ‹ ====
# from sklearn.linear_model import HuberRegressor
# from sklearn.preprocessing import PolynomialFeatures
#
# Nk_all = df.iloc[:, 13:32].apply(pd.to_numeric, errors='coerce')
# Tb_raw = df.iloc[:, 5].values
# Tb0 = 222.543
# poly = PolynomialFeatures(degree=2, include_bias=False)
# Nk_poly = poly.fit_transform(Nk_all)
#
# mask_tb = ~np.isnan(Tb_raw)
# model_Tb = HuberRegressor(max_iter=10000).fit(Nk_poly[mask_tb], np.exp(Tb_raw[mask_tb] / Tb0))
# Tb_pred_all = Tb0 * np.log(np.clip(model_Tb.predict(Nk_poly), 1e-6, None))
#
# # ==== 5. è®¡ç®— slope å¹¶åŠ å…¥ä¸» DataFrame ====
# T_ref = 298.15
# slope_values = (HVap_Tb_all - HVap_298_all) / (Tb_pred_all - T_ref)
# df["slope"] = slope_values
#
# # ==== 6. æ„å»ºè®­ç»ƒæ•°æ® ====
# X_total, y_total, material_ids, temperatures = [], [], [], []
#
# for i, row in df.iterrows():
#     material_id = row.iloc[0]
#     Nk = row[group_cols].values
#     temps = row[temp_cols].values
#     hvaps = row[hvap_cols].values
#     slope = row["slope"]
#
#     for T, Hv in zip(temps, hvaps):
#         if np.isnan(T) or np.isnan(Hv) or np.isnan(slope):
#             continue
#         features = np.concatenate([Nk, [T], [slope]])
#         X_total.append(features)
#         y_total.append(Hv)
#         material_ids.append(material_id)
#         temperatures.append(T)
#
# X_total = np.array(X_total)
# y_total = np.array(y_total)
#
# # ==== 7. æ‹Ÿåˆæ¨¡å‹ ====
# model = RandomForestRegressor(n_estimators=100, random_state=42)
# model.fit(X_total, y_total)
#
# # ==== 8. æ¨¡å‹è¯„ä¼° ====
# y_pred = model.predict(X_total)
# r2 = r2_score(y_total, y_pred)
# mse = mean_squared_error(y_total, y_pred)
# ard = np.mean(np.abs((y_pred - y_total) / y_total)) * 100  # ARD %
#
# print("\nğŸ“Š æ¨¡å‹è¯„ä¼°ï¼ˆåŸºå›¢ + æ¸©åº¦ + slope ç‰¹å¾ï¼‰ï¼š")
# print(f"RÂ²  = {r2:.4f}")
# print(f"MSE = {mse:.2f}")
# print(f"ARD = {ard:.2f}%")
#
# # ==== 9. ä¿å­˜ç»“æœ ====
# results = pd.DataFrame({
#     "Material_ID": material_ids,
#     "Temperature (K)": temperatures,
#     "Hvap_measured": y_total,
#     "Hvap_predicted": y_pred,
#     "Absolute Error": np.abs(y_total - y_pred),
#     "Relative Error (%)": 100 * np.abs((y_total - y_pred) / y_total)
# })
# results.to_excel("Volé¢„æµ‹ç»“æœ_åŠ slopeç‰¹å¾_RF.xlsx", index=False)
# print("âœ… å·²ä¿å­˜é¢„æµ‹ç»“æœä¸º: Volé¢„æµ‹ç»“æœ_åŠ slopeç‰¹å¾_RF.xlsx")
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# ==== 1. è¯»å–æ•°æ® ====
df = pd.read_excel("Pure component exergy 205.xlsx", sheet_name="Sheet1")

# ==== 2. å®šä¹‰åˆ— ====
group_cols = df.columns[12:31]   # ç¬¬14~25åˆ—ï¼šåŸºå›¢
temp_cols = df.columns[31:41]    # ç¬¬26~35åˆ—ï¼šæ¸©åº¦
v_cols = df.columns[41:51]       # ç¬¬36~45åˆ—ï¼šHvap

# ==== 3. å‡†å¤‡ slope æ‰€éœ€æ¨¡å‹è¾“å…¥ ====
df_298 = pd.read_excel("selected_25_descriptors_normal.xlsx")
X_298 = df_298.drop(columns=["ASPEN Exergy at 500k Temperature(j/mol)"])
rf_298 = RandomForestRegressor(random_state=42).fit(X_298, df_298["ASPEN Exergy at 500k Temperature(j/mol)"])
HVap_298_all = rf_298.predict(X_298)

df_Tb = pd.read_excel("selected_25_descriptors_boiling.xlsx")
X_Tb = df_Tb.drop(columns=["ASPEN Exergy at BoilingTemperature(j/mol)"])
rf_Tb = RandomForestRegressor(random_state=42).fit(X_Tb, df_Tb["ASPEN Exergy at BoilingTemperature(j/mol)"])
HVap_Tb_all = rf_Tb.predict(X_Tb)

# ==== 4. Tb æ¨¡å‹é¢„æµ‹ ====
from sklearn.linear_model import HuberRegressor
from sklearn.preprocessing import PolynomialFeatures

Nk_all = df.iloc[:, 12:31].apply(pd.to_numeric, errors='coerce')
Tb_raw = df.iloc[:, 5].values
Tb0 = 222.543
poly = PolynomialFeatures(degree=2, include_bias=False)
Nk_poly = poly.fit_transform(Nk_all)

mask_tb = ~np.isnan(Tb_raw)
model_Tb = HuberRegressor(max_iter=10000).fit(Nk_poly[mask_tb], np.exp(Tb_raw[mask_tb] / Tb0))
Tb_pred_all = Tb0 * np.log(np.clip(model_Tb.predict(Nk_poly), 1e-6, None))

# ==== 5. è®¡ç®— slope å¹¶åŠ å…¥ä¸» DataFrame ====
T_ref = 500
slope_values = (HVap_Tb_all - HVap_298_all) / (Tb_pred_all - T_ref)
df["slope"] = slope_values

# ==== 6. æ„å»ºè®­ç»ƒæ•°æ® ====
X_total, y_total, material_ids, temperatures = [], [], [], []

for i, row in df.iterrows():
    material_id = row.iloc[0]
    Nk = row[group_cols].values
    temps = row[temp_cols].values
    vols = row[v_cols].values
    slope = row["slope"]

    for T, vol in zip(temps, vols):
        if np.isnan(T) or np.isnan(vol) or np.isnan(slope):
            continue
        features = np.concatenate([Nk, [T], [slope]])
        X_total.append(features)
        y_total.append(vol)
        material_ids.append(material_id)
        temperatures.append(T)

X_total = np.array(X_total)
y_total = np.array(y_total)

# ==== 7. æ‹Ÿåˆæ¨¡å‹ ====
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_total, y_total)

# ==== 8. æ¨¡å‹è¯„ä¼° ====
y_pred = model.predict(X_total)
r2 = r2_score(y_total, y_pred)
mse = mean_squared_error(y_total, y_pred)
ard = np.mean(np.abs((y_pred - y_total) / y_total)) * 100  # ARD %

print("\nğŸ“Š æ¨¡å‹è¯„ä¼°ï¼ˆåŸºå›¢ + æ¸©åº¦ + slope ç‰¹å¾ï¼‰ï¼š")
print(f"RÂ²  = {r2:.4f}")
print(f"MSE = {mse:.2f}")
print(f"ARD = {ard:.2f}%")

# è®¡ç®—ç›¸å¯¹è¯¯å·®
relative_error = np.abs((y_pred - y_total) / y_total) * 100

# ç»Ÿè®¡ä¸åŒè¯¯å·®é˜ˆå€¼å†…çš„ç‚¹æ•°
within_1pct = np.sum(relative_error <= 1)
within_5pct = np.sum(relative_error <= 5)
within_10pct = np.sum(relative_error <= 10)

print(f"ç›¸å¯¹è¯¯å·® â‰¤ 1% çš„ç‚¹æ•°: {within_1pct}")
print(f"ç›¸å¯¹è¯¯å·® â‰¤ 5% çš„ç‚¹æ•°: {within_5pct}")
print(f"ç›¸å¯¹è¯¯å·® â‰¤ 10% çš„ç‚¹æ•°: {within_10pct}")

# ==== 9. ä¿å­˜ç»“æœ ====
results = pd.DataFrame({
    "Material_ID": material_ids,
    "Temperature (K)": temperatures,
    "Vol_measured": y_total,
    "Vol_predicted": y_pred,
    "Absolute Error": np.abs(y_total - y_pred),
    "Relative Error (%)": relative_error
})
results.to_excel("Exeé¢„æµ‹ç»“æœ_åŠ slopeç‰¹å¾_RF.xlsx", index=False)
print("âœ… å·²ä¿å­˜é¢„æµ‹ç»“æœä¸º: Exeé¢„æµ‹ç»“æœ_åŠ slopeç‰¹å¾_RF.xlsx")
# import pandas as pd
# import numpy as np
# from sklearn.linear_model import LinearRegression
# from sklearn.ensemble import RandomForestRegressor
# from sklearn.metrics import mean_squared_error, r2_score
#
# # 1. è¯»å–æ•°æ®
# file_path = "Pure component exergy 205.xlsx"
# df = pd.read_excel(file_path, sheet_name="Sheet1")
# df = df.dropna(subset=[df.columns[0]])
# df[df.columns[0]] = df[df.columns[0]].astype(int)
#
# # 2. åˆ—å®šä¹‰
# group_cols = df.columns[12:31]   # Måˆ°AE: åŸºå›¢æµ“åº¦
# temp_cols = df.columns[31:41]    # AFåˆ°AO: æ¸©åº¦
# target_cols = df.columns[41:51]  # APåˆ°AY: ç›®æ ‡å€¼ï¼ˆexergyï¼‰
#
# # === æ–œç‡å›å½’æ¨¡å‹è®­ç»ƒ ===
# slope_medians = []
# for i, row in df.iterrows():
#     temps = row[temp_cols].values
#     targets = row[target_cols].values
#     slopes = [(targets[t+1]-targets[t])/(temps[t+1]-temps[t]) for t in range(len(temps)-1)]
#     slope_medians.append(np.median(slopes))
#
# target_slopes = np.array(slope_medians)
#
# # æ–œç‡å›å½’æ¨¡å‹
# X_slope = df[group_cols].values  # æ³¨æ„è¿™é‡Œç”¨ numpy æ•°ç»„
# y_slope = target_slopes
#
# slope_model = LinearRegression()
# slope_model.fit(X_slope, y_slope)
#
# # æ–œç‡é¢„æµ‹åŠæŒ‡æ ‡
# predicted_slopes = slope_model.predict(X_slope)  # ç›´æ¥ç”¨ numpy æ•°ç»„ï¼Œä¸å¸¦åˆ—å
# mse_slope = mean_squared_error(y_slope, predicted_slopes)
# r2_slope = r2_score(y_slope, predicted_slopes)
# print(f"æ–œç‡æ¨¡å‹ MSE = {mse_slope:.4f}, RÂ² = {r2_slope:.4f}")
#
# # === Exergy é¢„æµ‹éšæœºæ£®æ—æ¨¡å‹ ===
# X_total, y_total, material_ids, temperatures = [], [], [], []
#
# for i, row in df.iterrows():
#     material_id = row.iloc[0]
#     Nk = row[group_cols].values
#     temps = row[temp_cols].values
#     ex_values = row[target_cols].values
#
#     # ç”¨ numpy æ•°ç»„é¢„æµ‹ slopeï¼Œé¿å…åˆ—åè­¦å‘Š
#     slope = slope_model.predict(Nk.reshape(1, -1))[0]
#
#     for T, val in zip(temps, ex_values):
#         if np.isnan(T) or np.isnan(val):
#             continue
#         features = np.concatenate([Nk, [T], [slope]])
#         X_total.append(features)
#         y_total.append(val)
#         material_ids.append(material_id)
#         temperatures.append(T)
#
# X_total = np.array(X_total)
# y_total = np.array(y_total)
#
# # éšæœºæ£®æ—è®­ç»ƒ
# rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
# rf_model.fit(X_total, y_total)
#
# # é¢„æµ‹ Exergy
# y_pred = rf_model.predict(X_total)
# mse_rf = mean_squared_error(y_total, y_pred)
# r2_rf = r2_score(y_total, y_pred)
# print(f"éšæœºæ£®æ—æ¨¡å‹ MSE = {mse_rf:.4f}, RÂ² = {r2_rf:.4f}")
#
# # ä¿å­˜é¢„æµ‹ç»“æœ
# results = pd.DataFrame({
#     "Material_ID": material_ids,
#     "Temperature (K)": temperatures,
#     "Ex_measured": y_total,
#     "Ex_predicted": y_pred
# })
# results.to_excel("Ex_predictions_with_slope_model_no_warning.xlsx", index=False)
# print("é¢„æµ‹ç»“æœå·²ä¿å­˜ä¸º: Ex_predictions_with_slope_model_no_warning.xlsx")
