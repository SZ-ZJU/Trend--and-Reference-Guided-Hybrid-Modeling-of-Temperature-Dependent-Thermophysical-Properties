import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.linear_model import HuberRegressor
from sklearn.ensemble import GradientBoostingRegressor
from scipy.optimize import least_squares
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import cross_val_score

# ========== è¯»å–æ•°æ® ========== #
df = pd.read_excel("vp209.xlsx", sheet_name='Sheet1')

# ========== å®šä¹‰åˆ— ========== #
group_cols = df.columns[12:31]  # ç¬¬13~31åˆ—ï¼šåŸºå›¢
temp_cols = df.columns[31:41]  # ç¬¬32~41åˆ—ï¼šæ¸©åº¦
v_cols = df.columns[41:51]  # ç¬¬42~51åˆ—ï¼šè’¸æ±½å‹

# ========== æ•°æ®é¢„å¤„ç† ========== #
# ç¡®ä¿æ•°å€¼åˆ—æ­£ç¡®è½¬æ¢
for col in temp_cols.tolist() + v_cols.tolist():
    df[col] = pd.to_numeric(df[col], errors='coerce')

# åŸºå›¢æ•°æ®
Nk = df.iloc[:, 12:31].values  # 19ä¸ªåŸºå›¢
T = df.iloc[:, 31:41].values
P_vp = df.iloc[:, 41:51].values

# ========== åˆ›å»ºæœ‰æ•ˆæ©ç  ========== #
# ä½¿ç”¨ä½ æä¾›çš„valid_mask
valid_mask = np.isfinite(P_vp) & (P_vp > 0)
valid_mask = valid_mask.all(axis=1)

# ========== æ„å»º Nk_poly ========== #
poly = PolynomialFeatures(degree=2, include_bias=False)
Nk_poly = poly.fit_transform(Nk)

# ========== Tb æ¨¡å‹ ========== #
Tb0 = 222.543
Tb_raw = df.iloc[:, 5].values

# ä½¿ç”¨valid_maskç­›é€‰æœ‰æ•ˆæ•°æ®
model_tb = HuberRegressor(max_iter=10000).fit(Nk_poly[valid_mask], np.exp(Tb_raw[valid_mask] / Tb0))
Tb_pred_all = Tb0 * np.log(np.clip(model_tb.predict(Nk_poly), 1e-6, None))

# ========== Pc æ¨¡å‹ ========== #
Pc_bar = df.iloc[:, 51].values[valid_mask]
MW = df.iloc[:, 4].values.reshape(-1, 1)  # å‡è®¾ç¬¬5åˆ—æ˜¯åˆ†å­é‡
MW_flat = MW[valid_mask].flatten()

Pc_poly = poly.fit_transform(Nk[valid_mask])


def residual_pc(params, X, MW, Pc_true):
    beta = params[:-1]
    beta3 = params[-1]
    y_pred = X @ beta
    x_pred = y_pred + 0.108998
    Pc_pred = 5.9827 + (1 / x_pred) ** 2 + beta3 * np.exp(1 / MW)
    return Pc_pred - Pc_true


params_init_pc = np.zeros(Pc_poly.shape[1] + 1)
result_pc = least_squares(residual_pc, x0=params_init_pc, args=(Pc_poly, MW_flat, Pc_bar), max_nfev=5000)
x_fit = Pc_poly @ result_pc.x[:-1] + 0.108998
Pc_pred_all = (5.9827 + (1 / x_fit) ** 2 + result_pc.x[-1] * np.exp(1 / MW_flat)) * 1e5  # Pa

# ========== è’¸æ±½å‹ä¸»æ¨¡å‹ ========== #
# ä½¿ç”¨åŸå§‹19ä¸ªåŸºå›¢
G = Nk  # (n, 19) åŸå§‹åŸºå›¢æ•°æ®
X_rows, y_rows = [], []
temp_eval = []  # ä¿å­˜æ¸©åº¦ç‚¹ä¿¡æ¯ç”¨äºè¯„ä¼°

# æ„å»ºè®­ç»ƒé›† - åªä½¿ç”¨æœ‰æ•ˆæ•°æ®
for i in np.where(valid_mask)[0]:  # åªéå†æœ‰æ•ˆç‰©è´¨
    for j, (tcol, vcol) in enumerate(zip(temp_cols, v_cols)):
        Tj = df.at[i, tcol]  # æ¸©åº¦å€¼
        Vj = df.at[i, vcol]  # è’¸æ±½å‹å€¼

        # è·³è¿‡NaNå€¼
        if np.isnan(Tj) or np.isnan(Vj) or Vj <= 0:
            continue

        Tb_i = Tb_pred_all[i]  # ç‰©è´¨içš„å‚è€ƒæ¸©åº¦
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å‚è€ƒè’¸æ±½å‹å€¼ï¼Œä½†åŸä»£ç ä¸­æ²¡æœ‰æä¾›
        # å‡è®¾æˆ‘ä»¬ä½¿ç”¨Antoineæ–¹ç¨‹æˆ–å…¶ä»–æ–¹æ³•è®¡ç®—å‚è€ƒè’¸æ±½å‹
        # è¿™é‡Œä½¿ç”¨ä¸€ä¸ªç®€åŒ–çš„å‚è€ƒå€¼
        V_ref = 101325  # æ ‡å‡†å¤§æ°”å‹ï¼ŒPa

        # ç‰¹å¾ï¼š(T - T_ref) Ã— G (ä½¿ç”¨åŸå§‹19ä¸ªåŸºå›¢)
        Xj = (Tj - Tb_i) * G[i]  # å½¢çŠ¶: (19,)

        # ç›®æ ‡ï¼šln(V) - ln(V_ref)
        # å¯¹è’¸æ±½å‹å–å¯¹æ•°ï¼Œå› ä¸ºè’¸æ±½å‹é€šå¸¸ç”¨å¯¹æ•°å½¢å¼å»ºæ¨¡
        yj = np.log(Vj) - np.log(V_ref)

        X_rows.append(Xj)
        y_rows.append(yj)
        temp_eval.append((tcol, vcol, i, j))

X_A = np.array(X_rows)  # (n_samples, 19)
y_A = np.array(y_rows)  # (n_samples,)

# è®­ç»ƒ A_k ç³»æ•°æ¨¡å‹
A_solver = HuberRegressor(fit_intercept=False, max_iter=5000)
A_solver.fit(X_A, y_A)
A_vec = A_solver.coef_  # é•¿åº¦19ï¼Œå¯¹åº”19ä¸ªåŸºå›¢

# ========== ç”ŸæˆåŸºå‡†è’¸æ±½å‹é¢„æµ‹ ========== #
V_pred_baseline = pd.DataFrame(index=df.index, columns=v_cols, dtype=float)

for i in range(len(df)):  # éå†æ‰€æœ‰ç‰©è´¨
    Tb_i = Tb_pred_all[i]  # ç‰©è´¨içš„å‚è€ƒæ¸©åº¦
    V_ref = 101325  # å‚è€ƒè’¸æ±½å‹å€¼ï¼ŒPa

    for j, (tcol, vcol) in enumerate(zip(temp_cols, v_cols)):
        Tj = df.at[i, tcol]  # æ¸©åº¦å€¼

        if np.isnan(Tj):
            V_pred_baseline.at[i, vcol] = np.nan
            continue

        # ç‰¹å¾ï¼š(T - T_ref) Ã— G (ä½¿ç”¨åŸå§‹19ä¸ªåŸºå›¢)
        Xj = (Tj - Tb_i) * G[i]

        # é¢„æµ‹ï¼šln(V_ref) + A_k Ã— (T - T_ref) Ã— Gï¼Œç„¶åå–æŒ‡æ•°
        ln_V_pred_j = np.log(V_ref) + Xj @ A_vec
        V_pred_j = np.exp(ln_V_pred_j)
        V_pred_baseline.at[i, vcol] = V_pred_j

# ========== æ®‹å·®æœºå™¨å­¦ä¹ æ¨¡å‹ ========== #
print("è®­ç»ƒæ®‹å·®æœºå™¨å­¦ä¹ æ¨¡å‹...")

# æ„å»ºæ®‹å·®è®­ç»ƒæ•°æ®é›†
residual_features = []
residual_targets = []
sample_info = []  # ä¿å­˜æ ·æœ¬ä¿¡æ¯ç”¨äºè¿½è¸ª

for tcol, vcol in zip(temp_cols, v_cols):
    Tj = df[tcol].to_numpy()
    Vj = df[vcol].to_numpy()
    # åªä½¿ç”¨æœ‰æ•ˆæ•°æ®
    msk = valid_mask & (~np.isnan(Tj)) & (~np.isnan(Vj)) & (Vj > 0)

    for i in np.where(msk)[0]:
        # åŸºç¡€ç‰¹å¾ï¼šåŸºå›¢ç»„æˆ
        base_features = list(G[i])

        # æ¸©åº¦ç›¸å…³ç‰¹å¾
        temp_features = [
            Tj[i],  # ç»å¯¹æ¸©åº¦
            Tj[i] - Tb_pred_all[i],  # ç›¸å¯¹äºå‚è€ƒæ¸©åº¦çš„å·®å€¼
            Tj[i] / Tb_pred_all[i] if Tb_pred_all[i] > 0 else 0,  # ç›¸å¯¹æ¸©åº¦
            np.log(Tj[i]) if Tj[i] > 0 else 0,  # æ¸©åº¦å¯¹æ•°
        ]

        # åŸºå‡†é¢„æµ‹å€¼ä½œä¸ºç‰¹å¾ï¼ˆå¯¹æ•°å°ºåº¦ï¼‰
        baseline_pred = V_pred_baseline.at[i, vcol]
        baseline_features = [np.log(baseline_pred) if baseline_pred > 0 else 0]

        # å‚è€ƒå€¼ç‰¹å¾
        ref_features = [
            Tb_pred_all[i],  # å‚è€ƒæ¸©åº¦
            np.log(101325),  # å‚è€ƒè’¸æ±½å‹çš„å¯¹æ•°
            Pc_pred_all[i] if i < len(Pc_pred_all) else 0,  # ä¸´ç•Œå‹åŠ›
        ]

        # åˆ†å­é‡ç‰¹å¾
        mw_features = [MW[i][0] if i < len(MW) else 0]

        # ç»„åˆæ‰€æœ‰ç‰¹å¾
        all_features = base_features + temp_features + baseline_features + ref_features + mw_features
        residual_features.append(all_features)

        # æ®‹å·®ç›®æ ‡ï¼šå®é™…å€¼çš„å¯¹æ•° - åŸºå‡†é¢„æµ‹çš„å¯¹æ•°
        residual = np.log(Vj[i]) - np.log(baseline_pred)
        residual_targets.append(residual)

        sample_info.append((i, tcol, vcol))

residual_features = np.array(residual_features)
residual_targets = np.array(residual_targets)

print(f"æ®‹å·®è®­ç»ƒé›†å½¢çŠ¶: {residual_features.shape}")
print(f"æ®‹å·®ç›®æ ‡å½¢çŠ¶: {residual_targets.shape}")

# æ ‡å‡†åŒ–ç‰¹å¾
scaler_residual = StandardScaler()
residual_features_scaled = scaler_residual.fit_transform(residual_features)

# è®­ç»ƒæ®‹å·®æ¨¡å‹ï¼ˆä½¿ç”¨æ¢¯åº¦æå‡å›å½’ï¼‰
residual_model = GradientBoostingRegressor(
    n_estimators=200,
    learning_rate=0.05,
    max_depth=5,
    min_samples_split=20,
    min_samples_leaf=10,
    random_state=42
)

# äº¤å‰éªŒè¯è¯„ä¼°æ®‹å·®æ¨¡å‹
cv_scores = cross_val_score(residual_model, residual_features_scaled, residual_targets,
                            cv=5, scoring='r2')
print(f"æ®‹å·®æ¨¡å‹äº¤å‰éªŒè¯ RÂ²: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")

# è®­ç»ƒæœ€ç»ˆæ®‹å·®æ¨¡å‹
residual_model.fit(residual_features_scaled, residual_targets)

# ========== ç”Ÿæˆæœ€ç»ˆé¢„æµ‹ï¼ˆåŸºå‡† + æ®‹å·®ä¿®æ­£ï¼‰ ========== #
V_pred_final = pd.DataFrame(index=df.index, columns=v_cols, dtype=float)

for tcol, vcol in zip(temp_cols, v_cols):
    Tj = df[tcol].to_numpy()

    # ä¸ºæ‰€æœ‰æ ·æœ¬æ„å»ºç‰¹å¾
    features_list = []
    valid_indices = []

    for i in range(len(df)):
        if np.isnan(Tj[i]) or (i < len(valid_mask) and not valid_mask[i]):
            continue

        # æ„å»ºä¸è®­ç»ƒæ—¶ç›¸åŒçš„ç‰¹å¾
        base_features = list(G[i])
        temp_features = [
            Tj[i],
            Tj[i] - Tb_pred_all[i],
            Tj[i] / Tb_pred_all[i] if Tb_pred_all[i] > 0 else 0,
            np.log(Tj[i]) if Tj[i] > 0 else 0,
        ]
        baseline_pred = V_pred_baseline.at[i, vcol]
        baseline_features = [np.log(baseline_pred) if baseline_pred > 0 else 0]
        ref_features = [
            Tb_pred_all[i],
            np.log(101325),
            Pc_pred_all[i] if i < len(Pc_pred_all) else 0,
        ]
        mw_features = [MW[i][0] if i < len(MW) else 0]

        all_features = base_features + temp_features + baseline_features + ref_features + mw_features
        features_list.append(all_features)
        valid_indices.append(i)

    if features_list:
        features_array = np.array(features_list)
        features_scaled = scaler_residual.transform(features_array)

        # é¢„æµ‹æ®‹å·®
        residual_pred = residual_model.predict(features_scaled)

        # æœ€ç»ˆé¢„æµ‹ï¼šln(V_final) = ln(V_baseline) + æ®‹å·®ï¼Œç„¶åå–æŒ‡æ•°
        for idx, residual_val in zip(valid_indices, residual_pred):
            baseline_pred = V_pred_baseline.at[idx, vcol]
            if baseline_pred > 0:
                ln_V_final = np.log(baseline_pred) + residual_val
                V_final = np.exp(ln_V_final)
                V_pred_final.at[idx, vcol] = V_final
            else:
                V_pred_final.at[idx, vcol] = np.nan

    # å¯¹äºæ— æ•ˆæ¸©åº¦ç‚¹ï¼Œä¿æŒNaN
    V_pred_final[vcol] = np.where(np.isnan(Tj), np.nan, V_pred_final[vcol])

# ========== è¯„ä¼°æ¨¡å‹æ€§èƒ½ ========== #
# åªä½¿ç”¨æœ‰æ•ˆæ•°æ®è¿›è¡Œè¯„ä¼°
print("\n=== åŸºå‡†æ¨¡å‹æ€§èƒ½ ===")
y_true_all, y_pred_baseline = [], []
for vcol in v_cols:
    # åªè€ƒè™‘æœ‰æ•ˆæ©ç ä¸ºTrueçš„æ•°æ®
    m = valid_mask & (~df[vcol].isna()) & (~V_pred_baseline[vcol].isna()) & (df[vcol] > 0) & (V_pred_baseline[vcol] > 0)
    if m.any():
        y_true_all.append(df.loc[m, vcol].to_numpy())
        y_pred_baseline.append(V_pred_baseline.loc[m, vcol].to_numpy())

if y_true_all and y_pred_baseline:
    y_true_all = np.concatenate(y_true_all)
    y_pred_baseline = np.concatenate(y_pred_baseline)

    # ä½¿ç”¨å¯¹æ•°å°ºåº¦è¯„ä¼°ï¼Œå› ä¸ºè’¸æ±½å‹é€šå¸¸ç”¨å¯¹æ•°å½¢å¼
    mse_baseline = mean_squared_error(np.log(y_true_all), np.log(y_pred_baseline))
    r2_baseline = r2_score(np.log(y_true_all), np.log(y_pred_baseline))
    print(f"åŸºå‡†æ¨¡å‹ - MSE (on ln(Vapor Pressure)): {mse_baseline:.6f}")
    print(f"åŸºå‡†æ¨¡å‹ - R2  (on ln(Vapor Pressure)): {r2_baseline:.6f}")
else:
    print("æ²¡æœ‰æœ‰æ•ˆæ•°æ®ç”¨äºåŸºå‡†æ¨¡å‹è¯„ä¼°")

print("\n=== æœ€ç»ˆæ¨¡å‹æ€§èƒ½ï¼ˆåŸºå‡† + æ®‹å·®ä¿®æ­£ï¼‰===")
y_true_all, y_pred_final = [], []
for vcol in v_cols:
    # åªè€ƒè™‘æœ‰æ•ˆæ©ç ä¸ºTrueçš„æ•°æ®
    m = valid_mask & (~df[vcol].isna()) & (~V_pred_final[vcol].isna()) & (df[vcol] > 0) & (V_pred_final[vcol] > 0)
    if m.any():
        y_true_all.append(df.loc[m, vcol].to_numpy())
        y_pred_final.append(V_pred_final.loc[m, vcol].to_numpy())

if y_true_all and y_pred_final:
    y_true_all = np.concatenate(y_true_all)
    y_pred_final = np.concatenate(y_pred_final)

    # ä½¿ç”¨å¯¹æ•°å°ºåº¦è¯„ä¼°ï¼Œå› ä¸ºè’¸æ±½å‹é€šå¸¸ç”¨å¯¹æ•°å½¢å¼
    mse_final = mean_squared_error(y_true_all, y_pred_final)
    r2_final = r2_score(y_true_all, y_pred_final)
    print(f"æœ€ç»ˆæ¨¡å‹ - MSE (on ln(Vapor Pressure)): {mse_final:.6f}")
    print(f"æœ€ç»ˆæ¨¡å‹ - R2  (on ln(Vapor Pressure)): {r2_final:.6f}")

    # æ”¹è¿›ç¨‹åº¦
    if 'r2_baseline' in locals():
        improvement = r2_final - r2_baseline
        print(f"\næ”¹è¿›ç¨‹åº¦: RÂ² æå‡äº† {improvement:.4f} ({improvement / r2_baseline * 100:.2f}%)")
else:
    print("æ²¡æœ‰æœ‰æ•ˆæ•°æ®ç”¨äºæœ€ç»ˆæ¨¡å‹è¯„ä¼°")

# ========== åˆ†æ¸©åº¦ç‚¹è¯„ä¼° ========== #
print("\nåˆ†æ¸©åº¦ç‚¹è¯„ä¼°:")
for tcol, vcol in zip(temp_cols, v_cols):
    # åªè€ƒè™‘æœ‰æ•ˆæ©ç ä¸ºTrueçš„æ•°æ®
    m = valid_mask & (~df[tcol].isna()) & (~df[vcol].isna()) & (~V_pred_final[vcol].isna()) & (df[vcol] > 0) & (
                V_pred_final[vcol] > 0)
    if m.any():
        v_true = df.loc[m, vcol].to_numpy()
        v_pred = V_pred_final.loc[m, vcol].to_numpy()
        # ä½¿ç”¨å¯¹æ•°å°ºåº¦
        mse_temp = mean_squared_error(v_true, v_pred)
        r2_temp = r2_score(v_true,v_pred)
        print(f"  {tcol}: MSE = {mse_temp:.6f}, R2 = {r2_temp:.6f}")

# ========== ä¿å­˜ç»“æœ ========== #
id_col = df.columns[0]  # ç‰©è´¨ID/åç§°æ‰€åœ¨åˆ—
out_path = "vapor_pressure_actual_vs_pred_with_residual_correction.xlsx"

rows = []
for idx, _ in df.iterrows():
    ID = df.at[idx, id_col]
    for j, (tcol, vcol) in enumerate(zip(temp_cols, v_cols), start=1):
        T_val = df.at[idx, tcol]
        V_act = df.at[idx, vcol]
        V_base = V_pred_baseline.at[idx, vcol] if pd.notna(V_pred_baseline.at[idx, vcol]) else np.nan
        V_final = V_pred_final.at[idx, vcol] if pd.notna(V_pred_final.at[idx, vcol]) else np.nan

        # è®¡ç®—è¯¯å·®ï¼ˆå¯¹æ•°å°ºåº¦ï¼‰
        if pd.notna(V_act) and pd.notna(V_base) and V_act > 0 and V_base > 0:
            err_base_log = np.log(V_base) - np.log(V_act)
        else:
            err_base_log = np.nan

        if pd.notna(V_act) and pd.notna(V_final) and V_act > 0 and V_final > 0:
            err_final_log = np.log(V_final) - np.log(V_act)
        else:
            err_final_log = np.nan

        residual_correction = (np.log(V_final) - np.log(V_base)) if (
                    pd.notna(V_final) and pd.notna(V_base) and V_final > 0 and V_base > 0) else np.nan

        rows.append({
            id_col: ID,
            "temp_index": j,
            "temp_col": tcol,
            "T": T_val,
            "Vapor_Pressure_actual": V_act,
            "Vapor_Pressure_baseline": V_base,
            "Vapor_Pressure_final": V_final,
            "error_baseline_log": err_base_log,
            "error_final_log": err_final_log,
            "residual_correction_log": residual_correction,
            "T_ref": Tb_pred_all[idx],
            "Pc_pred": Pc_pred_all[idx] if idx < len(Pc_pred_all) else np.nan,
            "is_valid": valid_mask[idx] if idx < len(valid_mask) else False
        })

long_compare = pd.DataFrame(rows).sort_values([id_col, "temp_index"])

with pd.ExcelWriter(out_path, engine="xlsxwriter") as writer:
    long_compare.to_excel(writer, sheet_name="compare_long", index=False)

print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {out_path}")
print(f"æœ‰æ•ˆæ•°æ®ç‚¹æ•°é‡: {np.sum(valid_mask)}")
# â€”â€” ç®€æ´ç›¸å¯¹è¯¯å·®ç»Ÿè®¡ï¼ˆæœ€ç»ˆï¼‰â€”â€”
relative_error_final = np.abs((y_pred_final - y_true_all) / y_true_all) * 100
within_1pct_final  = np.sum(relative_error_final <= 1)
within_5pct_final  = np.sum(relative_error_final <= 5)
within_10pct_final = np.sum(relative_error_final <= 10)
ard_final = np.mean(relative_error_final)  # å¹³å‡ç›¸å¯¹åå·®ï¼ˆ%ï¼‰

print("\nğŸ“Š æ€»æ¨¡å‹è¯„ä¼°ï¼ˆåŸºå‡† + æ®‹å·®ä¿®æ­£ï¼‰ï¼š")
print(f"RÂ²  = {r2_final:.4f}")
print(f"MSE = {mse_final:.6f}")
print(f"ARD = {ard_final:.2f}%")
print(f"âœ… è¯¯å·® â‰¤ 1% çš„æ•°æ®ç‚¹æ•°é‡: {within_1pct_final}")
print(f"âœ… è¯¯å·® â‰¤ 5% çš„æ•°æ®ç‚¹æ•°é‡: {within_5pct_final}")
print(f"âœ… è¯¯å·® â‰¤ 10% çš„æ•°æ®ç‚¹æ•°é‡: {within_10pct_final}")
